# ╔══════════════════════════════════════════════════════════════════════════════╗
# ║              DOCUMENTATION GENERATOR v2                                      ║
# ║                                                                              ║
# ║  Comprehensive documentation overhaul: audits codebase, creates new docs,   ║
# ║  generates browsable API reference, and verifies every claim against code.   ║
# ║                                                                              ║
# ║  14-Stage Execution Flow:                                                    ║
# ║                                                                              ║
# ║    Stage  1: Inventory (source, docs, commits, CLI)                         ║
# ║    Stage  2: Gap Analysis (stale, missing, inaccurate)                      ║
# ║    Stage  3: Documentation Plan (prioritized update list)                   ║
# ║    Stage  4: Infrastructure Setup (mkdocs-material, mkdocstrings)           ║
# ║    Stage  5: Fix setup.sh (daemon + docs flags)                             ║
# ║    Stage  6: Write Score Writing Guide (NEW)                                ║
# ║    Stage  7: Write Daemon Guide (NEW)                                       ║
# ║    Stage  8: Write Limitations Doc (NEW)                                    ║
# ║    Stage  9: Write Configuration Reference (NEW)                            ║
# ║    Stage 10: Update Existing Docs (README, guides, references)              ║
# ║    Stage 11: Generate Browsable Doc Site (mkdocs build)                     ║
# ║    Stage 12: Command Verification (run every CLI command)                   ║
# ║    Stage 13: Semantic Accuracy Audit (cross-ref all claims vs code)         ║
# ║    Stage 14: Commit & Push                                                   ║
# ║                                                                              ║
# ║  Usage:                                                                      ║
# ║    mozartd start --foreground &                                              ║
# ║    mozart run examples/docs-generator.yaml                                   ║
# ╚══════════════════════════════════════════════════════════════════════════════╝

name: "docs-generator"
description: "Comprehensive documentation overhaul — audit, create, verify, publish"

workspace: "./.docs-generator-workspace"

workspace_lifecycle:
  archive_on_fresh: true
  max_archives: 5

backend:
  type: claude_cli
  skip_permissions: true
  timeout_seconds: 3600  # 60 min per stage

cross_sheet:
  auto_capture_stdout: true
  max_output_chars: 8000
  lookback_sheets: 5
  capture_files:
    - "{{ workspace }}/*.md"

sheet:
  size: 1
  total_items: 14

  dependencies:
    2: [1]
    3: [2]
    4: [3]
    5: [4]
    6: [5]
    7: [6]
    8: [7]
    9: [8]
    10: [9]
    11: [10]
    12: [11]
    13: [12]
    14: [13]

parallel:
  enabled: false

retry:
  max_retries: 2

prompt:
  template: |
    {{ preamble }}

    {% if stage == 1 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 1: INVENTORY                                                         ║
    ║  "You can't document what you don't understand"                             ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Build a complete picture of what exists — source code, documentation,
    recent history, and CLI commands.

    **Step 1: Source inventory**
    ```bash
    # Map the source tree structure
    find src/ -name "*.py" -type f | sort

    # Count lines per module (top-level packages)
    for d in src/mozart/*/; do
      echo "$(find "$d" -name '*.py' -type f -exec cat {} + 2>/dev/null | wc -l) $d"
    done | sort -rn

    # List all public modules with classes/functions
    find src/ -name "*.py" -not -path "*__pycache__*" -type f | \
      xargs grep -l "^class \|^def \|^async def " 2>/dev/null | sort
    ```

    For each top-level package/subpackage, note:
    - Purpose (from module docstrings and __init__.py)
    - Key classes and functions (public API)
    - External dependencies

    **Step 2: Documentation inventory**
    ```bash
    # Find all documentation files
    find . -name "*.md" -not -path "./.git/*" -not -path "./.quality-*" \
      -not -path "./.docs-*" -not -path "./node_modules/*" -not -path "./site/*" | sort

    # Check docstring coverage in source
    for f in $(find src/ -name "*.py" -not -path "*__pycache__*" -type f | head -40); do
      HAS_DOCSTRING=$(python3 -c "
    import ast
    try:
      tree = ast.parse(open('$f').read())
      classes = [n for n in ast.walk(tree) if isinstance(n, (ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef))]
      with_ds = sum(1 for c in classes if ast.get_docstring(c))
      print(f'{with_ds}/{len(classes)} documented')
    except: print('parse error')
    " 2>/dev/null)
      echo "$f: $HAS_DOCSTRING"
    done
    ```

    Read each documentation file and note:
    - What it covers
    - Last meaningful update (check `git log --oneline -3 -- <file>`)
    - Whether it references current code accurately

    **Step 3: Commit history inventory (last 90 days)**
    ```bash
    # Recent commits — look for feature additions
    git log --oneline --since="90 days ago" | head -80

    # Commits that touched documentation
    git log --oneline --since="90 days ago" -- "*.md" "docs/" | head -30

    # New files added recently
    git log --diff-filter=A --since="90 days ago" --name-only --pretty=format: | \
      sort -u | grep -v "^$"

    # Files most frequently changed
    git log --since="90 days ago" --pretty=format: --name-only | \
      sort | uniq -c | sort -rn | head -20
    ```

    **Step 4: CLI command inventory**
    ```bash
    # Run --help on every command and capture line counts
    for cmd in \
      "mozart --help" \
      "mozart run --help" \
      "mozart resume --help" \
      "mozart pause --help" \
      "mozart modify --help" \
      "mozart status --help" \
      "mozart validate --help" \
      "mozart list --help" \
      "mozart logs --help" \
      "mozart errors --help" \
      "mozart diagnose --help" \
      "mozart recover --help" \
      "mozart history --help" \
      "mozart dashboard --help" \
      "mozart mcp --help" \
      "mozart config --help" \
      "mozart patterns-list --help" \
      "mozart patterns-why --help" \
      "mozart patterns-entropy --help" \
      "mozart patterns-budget --help" \
      "mozart learning-stats --help" \
      "mozart learning-insights --help" \
      "mozart learning-drift --help" \
      "mozart learning-epistemic-drift --help" \
      "mozart learning-activity --help" \
      "mozart entropy-status --help" \
      "mozartd --help" \
      "mozartd start --help" \
      "mozartd stop --help" \
      "mozartd status --help"; do
      LINES=$($cmd 2>&1 | wc -l)
      echo "$cmd: $LINES lines"
    done
    ```

    **Step 5: Validate all example configs**
    ```bash
    for f in examples/*.yaml; do
      echo -n "$f: "
      mozart validate "$f" 2>&1 | tail -1
    done
    ```

    **Step 6: Inventory any external skill files**

    Check if there are Claude Code skill files that reference this project:
    ```bash
    find ~/.claude/skills/ -name "*.md" -exec grep -l "mozart" {} \; 2>/dev/null
    ```

    If any skill files reference this project, read them and note what
    commands/features they document (they may be stale).

    **Output to:** {{ workspace }}/01-inventory.md

    Format as markdown with these sections:
    - Source Modules (table: Package | Files | LOC | Purpose)
    - Documentation Files (table: File | Covers | Last Updated | Accurate?)
    - Recent Features from commits (table: Feature | Date | Documented?)
    - CLI Commands (table: Command | Help Lines | In Docs?)
    - Example Configs (table: File | Valid? | Purpose)
    - Docstring Coverage (table: File | Documented/Total | Coverage%)

    {% elif stage == 2 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 2: GAP ANALYSIS                                                      ║
    ║  "Find every lie the docs tell"                                             ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Read {{ workspace }}/01-inventory.md and cross-reference what's implemented
    against what's documented.

    **Step 1: Feature-to-docs mapping**

    For each feature from the inventory, check whether it appears in:
    - README.md
    - CLAUDE.md
    - docs/*.md files
    - CLI --help output

    **Step 2: Stale documentation detection**

    Read each documentation file and verify claims against current code:
    - References to files/functions that no longer exist
    - Outdated terminology
    - Descriptions that don't match current behavior
    - Missing mentions of new parameters or options
    - Config examples that use deprecated fields

    **Step 3: Critical gap: daemon requirement**

    Specifically audit:
    - Does README.md explain that `mozart run` requires a running daemon?
    - Does getting-started.md include `mozartd start`?
    - Does CLAUDE.md mention the daemon requirement?
    - Does setup.sh install daemon dependencies and mention mozartd?
    - Is `--escalation` documented as incompatible with daemon?

    **Step 4: Missing documentation categories**

    Check if these exist:
    - Score/concert writing guide (how to author YAML scores)
    - Daemon operation guide (mozartd lifecycle, monitoring)
    - Known limitations doc (what doesn't work yet)
    - Complete configuration reference (all Pydantic config fields)
    - Browsable API reference (auto-generated from source)

    **Step 5: External skill file accuracy**

    If any Claude Code skill files reference this project (found in stage 1),
    verify:
    - Are all commands they list still valid?
    - Are the examples accurate?
    - Do they mention daemon requirement?

    **Output to:** {{ workspace }}/02-gap-analysis.md

    Format with these sections:
    - Undocumented Features (table: Feature | Source | Impact | Priority)
    - Stale Documentation (table: File | Section | What's Wrong | Fix)
    - Daemon Coverage Gaps (bullet list of missing daemon info)
    - Missing Documentation (table: Document | Purpose | Priority)
    - Skill Accuracy Issues (bullet list)
    - Severity Summary (Critical/High/Medium/Low counts)

    {% elif stage == 3 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 3: DOCUMENTATION PLAN                                                ║
    ║  "Fix the docs that matter most first"                                      ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Read {{ workspace }}/02-gap-analysis.md and create a prioritized plan
    for all remaining stages (4-13).

    **Prioritization rules:**
    1. Critical gaps first — anything that blocks usage
    2. Stale docs second — wrong info is worse than missing info
    3. High-traffic files third — README, getting-started, CLAUDE.md
    4. New features fourth — recently added but undocumented

    **Plan content for each remaining stage:**

    **Stage 4 (Infrastructure):**
    - What mkdocs plugins to install
    - mkdocs.yml nav structure
    - gen_ref_pages.py for API auto-discovery

    **Stage 5 (setup.sh):**
    - --daemon flag (install daemon extra, verify mozartd)
    - --docs flag (install docs extra, run mkdocs build)
    - Updated help text and completion summary

    **Stage 6 (Score Writing Guide):** docs/score-writing-guide.md
    - 6 score archetypes with real examples from examples/
    - Template variable reference
    - All 5 validation types
    - Fan-out, dependencies, cross-sheet context
    - Concert chaining, on_success hooks
    - Testing (validate, --dry-run)

    **Stage 7 (Daemon Guide):** docs/daemon-guide.md
    - Why daemon? Architecture overview
    - Quick start, daemon requirement
    - Configuration, monitoring, troubleshooting
    - What's built but NOT wired (scheduler, rate coordinator)
    - Migration from pre-daemon usage

    **Stage 8 (Limitations):** docs/limitations.md
    - Daemon required, no standalone mode
    - --escalation blocked with daemon
    - Phase 3 components not wired
    - Single-machine only
    - Other known limitations

    **Stage 9 (Config Reference):** docs/configuration-reference.md
    - Every Pydantic model field from src/mozart/core/config/
    - DaemonConfig from src/mozart/daemon/config.py
    - Organized by section with types, defaults, descriptions

    **Stage 10 (Update Existing Docs):**
    - README.md: daemon section, license, architecture
    - docs/getting-started.md: daemon quick start
    - docs/cli-reference.md: verify all commands vs --help
    - docs/mozart-reference.md: remove WARNING, rewrite for daemon era
    - CLAUDE.md: key files, test count, validation types

    **Output to:** {{ workspace }}/03-docs-plan.md

    Format with detailed per-stage plans including:
    - Exact file targets
    - Section-level outline of content
    - Priority and effort estimates

    {% elif stage == 4 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 4: INFRASTRUCTURE SETUP                                              ║
    ║  "Build the doc site foundation"                                            ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Set up the mkdocs-material documentation infrastructure.

    **Step 1: Install docs dependencies**
    ```bash
    pip install -e ".[docs]" 2>&1 | tail -5
    ```

    **Step 2: Verify installation**
    ```bash
    python -c "import mkdocs; print('mkdocs:', mkdocs.__version__)"
    python -c "import mkdocstrings; print('mkdocstrings OK')"
    python -c "import mkdocs_gen_files; print('gen-files OK')"
    ```

    **Step 3: Verify mkdocs.yml exists and is valid**

    Read `mkdocs.yml` at the project root. It should already exist (created
    before this score was run). Verify it has:
    - material theme configured
    - mkdocstrings plugin with python handler
    - gen-files plugin pointing to docs/scripts/gen_ref_pages.py
    - literate-nav plugin
    - Nav structure with guides + reference sections

    If mkdocs.yml does NOT exist, create it with the above configuration.

    **Step 4: Verify gen_ref_pages.py exists**

    Check `docs/scripts/gen_ref_pages.py`. It should walk `src/mozart/` and
    generate API reference pages. If missing, create it using the standard
    mkdocstrings pattern.

    **Step 5: Test a minimal build**
    ```bash
    # Try building — may warn about missing pages but should not error
    mkdocs build 2>&1 | tail -20
    ```

    If `mkdocs build` fails because new guide pages (daemon-guide.md, etc.)
    don't exist yet, create placeholder files:
    ```bash
    for f in docs/daemon-guide.md docs/score-writing-guide.md \
             docs/configuration-reference.md docs/limitations.md; do
      if [ ! -f "$f" ]; then
        echo "# $(basename "$f" .md | tr '-' ' ' | sed 's/\b\w/\u&/g')" > "$f"
        echo "" >> "$f"
        echo "This page will be populated in a later stage." >> "$f"
      fi
    done
    ```

    Then retry the build.

    **Output to:** {{ workspace }}/04-infrastructure.md

    Report: what was installed, build output, any issues fixed.

    {% elif stage == 5 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 5: FIX setup.sh                                                      ║
    ║  "The front door needs daemon awareness"                                    ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Read `setup.sh` at the project root. Update it to support the daemon era.

    **Changes needed:**

    1. **Add `--daemon` flag:**
       - Installs `.[daemon]` extra (psutil)
       - Verifies `mozartd` command is available after install
       - Adds mozartd to the completion summary

    2. **Add `--docs` flag:**
       - Installs `.[docs]` extra (mkdocs-material stack)
       - Runs `mkdocs build` to verify the doc site generates
       - Adds doc site info to completion summary

    3. **Update help text:**
       - Add --daemon and --docs to Options section
       - Add examples: `./setup.sh --daemon`, `./setup.sh --docs`
       - Add mozartd to Prerequisites mention

    4. **Update completion summary:**
       - If daemon installed, show: `mozartd start` / `mozartd status`
       - If docs installed, show: `mkdocs serve` (browse at localhost:8000)
       - Update "To run your first job" to include `mozartd start` step

    5. **Update example config reference:**
       - The script references `examples/simple-sheet.yaml` — verify this exists
       - If not, use a valid example file

    **Rules:**
    - Read the ENTIRE file before making changes
    - Preserve existing style (color codes, log functions, set -euo pipefail)
    - Keep the script idempotent — re-running should not break anything
    - Verify syntax after changes: `bash -n setup.sh`

    **Output to:** {{ workspace }}/05-setup-fixed.md

    Report: what was changed, bash -n result.

    {% elif stage == 6 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 6: WRITE SCORE WRITING GUIDE                                         ║
    ║  "Teach users to compose their own scores"                                  ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Create `docs/score-writing-guide.md` — a comprehensive guide to authoring
    Mozart score YAML files.

    **Research first:**

    Read these source files to understand the complete config model:
    ```bash
    cat src/mozart/core/config/job.py
    cat src/mozart/core/config/execution.py
    cat src/mozart/core/config/orchestration.py
    cat src/mozart/core/config/backend.py
    cat src/mozart/core/config/learning.py
    cat src/mozart/core/config/workspace.py
    cat src/mozart/prompts/templating.py
    ```

    Read 3-4 example scores to see real patterns:
    ```bash
    cat examples/sheet-review.yaml
    cat examples/parallel-research-fanout.yaml
    cat examples/quality-continuous.yaml
    cat examples/docs-generator.yaml  # This very score!
    ```

    **Required sections:**

    1. **What is a Score?**
       - YAML config → multi-stage Claude execution
       - Analogy: musical score orchestrates instruments

    2. **The 6 Score Archetypes** (with real examples from examples/):
       - Linear Pipeline (sheet-review: sequential stages)
       - Parallel Research (parallel-research-fanout: fan-out stages)
       - Quality Assurance (quality-continuous: audit + parallel experts + synthesis)
       - Content Generation (nonfiction-book, strategic-plan: long-form output)
       - Code Automation (fix-deferred-issues, issue-fixer: code modification)
       - Self-Documenting (docs-generator: meta — generates its own docs)

    3. **Anatomy of a Score** (field-by-field reference):
       - name, description
       - workspace, workspace_lifecycle
       - backend (type, skip_permissions, timeout_seconds, model)
       - sheet (size, total_items, dependencies, fan_out)
       - parallel (enabled, max_concurrent)
       - retry (max_retries, backoff)
       - cross_sheet (auto_capture_stdout, max_output_chars, lookback_sheets, capture_files)
       - prompt (template, variables, preamble, stakes, thinking_method)
       - validations (the 5 types)

    4. **Template Variables Reference:**
       - Core: sheet_num, total_sheets, start_item, end_item, workspace
       - Fan-out: stage, instance, fan_count, total_stages
       - Cross-sheet: previous_outputs, previous_files
       - User-defined: prompt.variables

    5. **Validation Types** (field-by-field):
       - file_exists (path, description, stage, condition)
       - file_modified (path, description, stage, condition)
       - content_contains (path, pattern, description, stage, condition)
       - content_regex (path, pattern, description, stage, condition)
       - command_succeeds (command, working_directory, description, stage, condition)

    6. **Fan-Out & Dependencies:**
       - How fan_out expands stages into parallel instances
       - Dependency syntax: `{sheet: [dependencies]}`
       - Cross-sheet context passing

    7. **Concert Chaining & Hooks:**
       - on_success hooks for score chaining
       - Conductor/concert configuration (if applicable)

    8. **Testing Your Score:**
       - `mozart validate <file>` — structural validation
       - `mozart run <file> --dry-run` — execution simulation
       - `setsid` for detached execution
       - Common validation errors and fixes

    9. **Best Practices:**
       - Use setsid for long-running scores
       - Set appropriate timeouts per stage
       - Use preamble for consistent context
       - Put validation markers in prompt instructions
       - Validate all examples: `mozart validate examples/*.yaml`

    **Rules:**
    - Use REAL examples from the examples/ directory, not hypothetical ones
    - Cross-reference every field name against the Pydantic models
    - Keep it scannable with tables, code blocks, and clear headings
    - This should be the definitive "how to write a score" document

    **Output to:** {{ workspace }}/06-score-guide.md

    Report: sections written, examples referenced, field count.

    {% elif stage == 7 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 7: WRITE DAEMON GUIDE                                                ║
    ║  "The daemon is now mandatory — document it properly"                       ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Create `docs/daemon-guide.md` — the complete guide to Mozart's daemon mode.

    **Research first:**

    Read the daemon source:
    ```bash
    cat src/mozart/daemon/config.py
    cat src/mozart/daemon/process.py
    head -100 src/mozart/daemon/manager.py
    head -100 src/mozart/daemon/job_service.py
    cat src/mozart/daemon/detect.py
    cat src/mozart/daemon/health.py
    head -80 src/mozart/daemon/scheduler.py
    head -80 src/mozart/daemon/rate_coordinator.py
    head -80 src/mozart/daemon/backpressure.py
    cat src/mozart/daemon/ipc/protocol.py
    ```

    Read how the CLI detects and requires daemon:
    ```bash
    cat src/mozart/cli/commands/run.py
    grep -n "daemon\|mozartd" src/mozart/cli/commands/*.py
    ```

    **Required sections:**

    1. **Why a Daemon?**
       - Centralized resource management
       - Cross-job rate limit coordination (future)
       - Persistent job registry
       - Health monitoring and backpressure

    2. **Quick Start:**
       ```bash
       # Start daemon
       mozartd start --foreground  # or: mozartd start (background)

       # Run a job
       mozart run my-score.yaml

       # Check status
       mozartd status

       # Stop daemon
       mozartd stop
       ```

    3. **The Daemon Requirement:**
       - `mozart run` requires a running daemon (verified via Unix socket)
       - `mozart run --dry-run` works WITHOUT a daemon
       - `mozart validate` works WITHOUT a daemon
       - How auto-detection works (socket check at default IPC path)

    4. **Architecture:**
       - Process model (daemon process, IPC server, job workers)
       - Manager → Registry → JobService pipeline
       - IPC layer (Unix socket + JSON-RPC 2.0)
       - Health checks and monitoring
       - Backpressure (memory-based load management)

    5. **Configuration:**
       - DaemonConfig fields (from src/mozart/daemon/config.py)
       - Default paths (socket, PID file, log)
       - Environment variables (if any)

    6. **Monitoring:**
       - `mozartd status` — is daemon running?
       - `mozartd health` — health check details
       - `mozartd jobs` — list active jobs
       - `mozartd resources` — resource usage
       - Log location: `~/.mozart/mozartd.log`

    7. **What's Built But NOT Yet Wired (Phase 3):**
       - GlobalScheduler: cross-job sheet scheduling with priority
       - RateLimitCoordinator: shares rate limit state across jobs
       - Both are built, tested, but not integrated into the execution path

    8. **Migration from Pre-Daemon Usage:**
       - Before: `mozart run my-score.yaml`
       - After: `mozartd start && mozart run my-score.yaml`
       - setup.sh now has `--daemon` flag

    9. **Troubleshooting:**
       - "Socket not found" — daemon not running, start it
       - "Stale PID file" — daemon crashed, `mozartd stop && mozartd start`
       - Permission errors on socket file
       - Port/socket conflicts
       - --escalation incompatible with daemon

    **Rules:**
    - Verify every mozartd command by reading the CLI source
    - Don't document Phase 3 features as if they're active
    - Use actual DaemonConfig field names from the Pydantic model
    - Include the daemon detection flow from detect.py

    **Output to:** {{ workspace }}/07-daemon-guide.md

    Report: sections written, commands documented, Phase 3 items noted.

    {% elif stage == 8 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 8: WRITE LIMITATIONS DOC                                             ║
    ║  "Honesty builds trust — document what doesn't work"                        ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Create `docs/limitations.md` — an honest document of known limitations,
    caveats, and incomplete features.

    **Research first:**

    Check for known issues:
    ```bash
    # Escalation blocking
    grep -n "escalation" src/mozart/cli/commands/run.py

    # Phase 3 wiring status
    grep -rn "not.*wired\|TODO\|FIXME\|HACK\|XXX" src/mozart/daemon/ | head -20

    # Backend limitations
    grep -n "class.*Backend\|class.*Protocol" src/mozart/backends/*.py

    # Dashboard state
    ls src/mozart/dashboard/

    # Learning system complexity
    ls src/mozart/learning/store/
    ```

    **Required limitations to document:**

    1. **Daemon Required for Execution**
       - `mozart run` requires `mozartd` — no standalone execution mode
       - Only `--dry-run` and `mozart validate` work without daemon
       - Rationale: centralized resource management

    2. **Escalation Incompatible with Daemon**
       - `--escalation` flag is explicitly blocked when daemon routes jobs
       - The escalation feature works in theory but not through daemon path

    3. **Phase 3 Components Not Wired**
       - GlobalScheduler: built and tested, not integrated
       - RateLimitCoordinator: built and tested, no data source
       - These exist in code but don't affect execution

    4. **Single-Machine Only**
       - No distributed execution across multiple machines
       - Daemon binds to local Unix socket
       - Worktree isolation is per-machine

    5. **Claude-Centric Design**
       - Error classification tuned for Claude CLI output patterns
       - Rate limit detection patterns are Claude-specific
       - API backend exists but less battle-tested

    6. **Learning System Complexity**
       - Multi-table SQLite schema (14+ store modules)
       - Drift detection, entropy tracking, epistemic monitoring
       - May be overengineered for simple use cases

    7. **Dashboard UI**
       - Functional but minimal
       - No real-time streaming (batch-oriented updates)
       - SSE endpoint exists but UI coverage is limited

    8. **Runner Architecture**
       - 8 mixins via multiple inheritance (complex debugging)
       - Sheet/lifecycle/recovery/cost/isolation/patterns all interleaved

    9. **No Output Streaming**
       - Execution is batch-oriented
       - stdout/stderr captured after completion, not streamed
       - `stdout_tail` limited to last ~10KB

    10. **Validation Conditions**
        - Only supports: `sheet_num >= N`, `sheet_num == N`, `sheet_num > N`
        - No complex boolean expressions
        - No fan-out-aware conditions (stage + instance)

    **Format:**
    Each limitation should have:
    - Clear title
    - What the limitation IS
    - WHY it exists (technical reason or design choice)
    - WORKAROUND if one exists
    - STATUS (permanent design choice vs planned fix)

    **Output to:** {{ workspace }}/08-limitations.md

    Report: limitations documented, workarounds provided.

    {% elif stage == 9 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 9: WRITE CONFIGURATION REFERENCE                                     ║
    ║  "Every field, every type, every default"                                   ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Create `docs/configuration-reference.md` — a complete reference of every
    configuration field in Mozart score YAML files.

    **Research: Read ALL Pydantic config models**
    ```bash
    # Core config models
    cat src/mozart/core/config/backend.py
    cat src/mozart/core/config/execution.py
    cat src/mozart/core/config/orchestration.py
    cat src/mozart/core/config/job.py
    cat src/mozart/core/config/learning.py
    cat src/mozart/core/config/workspace.py

    # Daemon config
    cat src/mozart/daemon/config.py
    ```

    **For EACH Pydantic model, extract:**
    - Field name
    - Python type (str, int, bool, Optional[...], list[...], dict[...])
    - Default value
    - Description (from Field(..., description=) or docstring)
    - Constraints (ge=, le=, min_length=, pattern=, etc.)

    **Required sections (organized by YAML top-level key):**

    1. **Top-Level Fields:** name, description
    2. **workspace** and **workspace_lifecycle**
    3. **backend:** type, model, skip_permissions, timeout_seconds, etc.
    4. **sheet:** size, total_items, dependencies, fan_out
    5. **parallel:** enabled, max_concurrent
    6. **retry:** max_retries, backoff_base, backoff_max, etc.
    7. **rate_limit:** detection patterns, wait times, etc.
    8. **circuit_breaker:** failure thresholds, etc.
    9. **cost_limits:** max_cost_per_sheet, etc.
    10. **cross_sheet:** auto_capture_stdout, max_output_chars, lookback_sheets, capture_files
    11. **prompt:** template, variables, preamble, stakes, thinking_method
    12. **validations:** The 5 validation types (field-by-field)
    13. **isolation:** enabled, mode, cleanup_on_success, etc.
    14. **grounding:** grounding config fields
    15. **conductor/concert:** orchestration fields
    16. **notifications:** notification config
    17. **learning:** learning config fields
    18. **DaemonConfig:** (separate section for mozartd configuration)

    **Format each section as a table:**
    ```markdown
    | Field | Type | Default | Description |
    |-------|------|---------|-------------|
    | name  | str  | required | Job name   |
    ```

    **Rules:**
    - Every field must come from actual Pydantic model source code
    - Include Field validators and constraints
    - Show YAML example snippets for complex nested configs
    - Cross-reference validation types with the score-writing guide

    **Output to:** {{ workspace }}/09-config-reference.md

    Report: models documented, field count per section.

    {% elif stage == 10 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 10: UPDATE EXISTING DOCS                                             ║
    ║  "Make the old docs match the new reality"                                  ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Read {{ workspace }}/03-docs-plan.md for the planned updates, then
    update existing documentation files.

    **Files to update:**

    1. **README.md**
       - Add daemon section (mozartd start, the requirement)
       - Update architecture overview if stale
       - Update license references from MIT to AGPL-3.0
       - Link to new docs (daemon guide, score writing guide, etc.)
       - Link to browsable doc site (mkdocs serve)
       - Verify all file paths and commands still work

    2. **docs/getting-started.md**
       - Add daemon quick start: mozartd start before mozart run
       - Update CLI examples for daemon era
       - Verify example config references exist
       - Add link to daemon guide for details

    3. **docs/cli-reference.md**
       - Run `--help` for EVERY command and compare to what's documented
       - Update any mismatches
       - Add missing commands (learning-*, patterns-*, entropy-*)
       - Add mozartd commands section

    4. **docs/mozart-reference.md**
       - Remove the WARNING header about being outdated
       - Rewrite for daemon-first architecture
       - Update component descriptions
       - Note Phase 3 status (scheduler, rate coordinator)

    5. **CLAUDE.md**
       - Update key files table if any files moved/renamed
       - Ensure validation types list is accurate
       - Update test count if changed
       - Add reference to new docs (daemon guide, etc.)

    **Rules:**
    - Read EACH file completely before modifying
    - Preserve existing accurate content
    - Match existing style and formatting
    - Verify every file path, function name, CLI command you reference
    - Do NOT add speculative future-work sections

    **Output to:** {{ workspace }}/10-existing-docs-updated.md

    Report: changes per file, what was preserved, what was updated.

    {% elif stage == 11 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 11: GENERATE BROWSABLE DOC SITE                                      ║
    ║  "One unified, searchable documentation portal"                             ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Generate the mkdocs-material documentation site.

    **Step 1: Verify all doc pages exist**
    ```bash
    # Check that all pages referenced in mkdocs.yml nav exist
    for f in docs/index.md docs/getting-started.md docs/daemon-guide.md \
             docs/score-writing-guide.md docs/configuration-reference.md \
             docs/limitations.md docs/cli-reference.md docs/mozart-reference.md \
             docs/MCP-INTEGRATION.md docs/DISTRIBUTED-LEARNING-ARCHITECTURE.md \
             docs/TOKEN-COMPRESSION-STRATEGIES.md docs/OPUS-CONVERGENCE-ANALYSIS.md; do
      if [ -f "$f" ]; then echo "✓ $f"
      else echo "✗ MISSING: $f"
      fi
    done
    ```

    **Step 2: Build the site**
    ```bash
    mkdocs build 2>&1
    ```

    If errors occur (broken references, missing pages), fix them:
    - Create missing placeholder pages if needed
    - Fix broken cross-references in mkdocs.yml
    - Re-run `mkdocs build` until clean

    **Step 3: Verify output**
    ```bash
    # Check key output files exist
    ls -la site/index.html
    ls site/reference/ 2>/dev/null | head -10
    ls site/daemon-guide/ 2>/dev/null
    ls site/score-writing-guide/ 2>/dev/null

    # Count generated pages
    find site/ -name "*.html" | wc -l
    ```

    **Step 4: Verify search index**
    ```bash
    ls -la site/search/search_index.json 2>/dev/null
    ```

    **Output to:** {{ workspace }}/11-doc-site.md

    Report: build output, page count, any errors fixed.

    {% elif stage == 12 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 12: COMMAND VERIFICATION                                             ║
    ║  "Run every command. Trust nothing."                                        ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Actually run EVERY CLI command listed in the documentation and verify
    the output matches what the docs claim.

    **Step 1: Run --help for every mozart command**
    ```bash
    echo "=== Mozart CLI Commands ==="
    for cmd in \
      "mozart --help" \
      "mozart run --help" \
      "mozart resume --help" \
      "mozart pause --help" \
      "mozart modify --help" \
      "mozart status --help" \
      "mozart validate --help" \
      "mozart list --help" \
      "mozart logs --help" \
      "mozart errors --help" \
      "mozart diagnose --help" \
      "mozart recover --help" \
      "mozart history --help" \
      "mozart dashboard --help" \
      "mozart mcp --help" \
      "mozart config --help"; do
      echo "--- $cmd ---"
      if $cmd 2>&1 | head -5; then
        echo "RESULT: PASS"
      else
        echo "RESULT: FAIL (exit code $?)"
      fi
      echo ""
    done
    ```

    **Step 2: Run --help for every learning command**
    ```bash
    echo "=== Learning Commands ==="
    for cmd in \
      "mozart patterns-list --help" \
      "mozart patterns-why --help" \
      "mozart patterns-entropy --help" \
      "mozart patterns-budget --help" \
      "mozart learning-stats --help" \
      "mozart learning-insights --help" \
      "mozart learning-drift --help" \
      "mozart learning-epistemic-drift --help" \
      "mozart learning-activity --help" \
      "mozart entropy-status --help"; do
      echo "--- $cmd ---"
      if $cmd 2>&1 | head -3; then
        echo "RESULT: PASS"
      else
        echo "RESULT: FAIL (exit code $?)"
      fi
      echo ""
    done
    ```

    **Step 3: Run --help for every mozartd command**
    ```bash
    echo "=== Daemon Commands ==="
    for cmd in \
      "mozartd --help" \
      "mozartd start --help" \
      "mozartd stop --help" \
      "mozartd status --help"; do
      echo "--- $cmd ---"
      if $cmd 2>&1 | head -5; then
        echo "RESULT: PASS"
      else
        echo "RESULT: FAIL (exit code $?)"
      fi
      echo ""
    done
    ```

    **Step 4: Validate ALL example configs**
    ```bash
    echo "=== Example Config Validation ==="
    for f in examples/*.yaml; do
      echo -n "$f: "
      if mozart validate "$f" 2>&1 | grep -q "Valid\|valid\|✓"; then
        echo "VALID"
      else
        echo "INVALID or WARNING"
        mozart validate "$f" 2>&1 | tail -3
      fi
    done
    ```

    **Step 5: Validate this score itself**
    ```bash
    echo "=== Self-Validation ==="
    mozart validate examples/docs-generator.yaml 2>&1
    ```

    **Step 6: Verify setup.sh syntax**
    ```bash
    echo "=== setup.sh Syntax Check ==="
    bash -n setup.sh 2>&1 && echo "PASS" || echo "FAIL"
    ```

    **Step 7: Cross-check docs vs --help**

    Read docs/cli-reference.md. For each command documented there, compare
    the documented options with the actual --help output. Note any mismatches.

    **Output to:** {{ workspace }}/12-command-verification.md

    Format:
    ```markdown
    # Command Verification Results

    ## Mozart CLI Commands
    | Command | --help Works | Documented | Match |
    |---------|-------------|------------|-------|

    ## Learning Commands
    | Command | --help Works | Documented | Match |
    |---------|-------------|------------|-------|

    ## Daemon Commands
    | Command | --help Works | Documented | Match |
    |---------|-------------|------------|-------|

    ## Example Configs
    | File | Valid | Notes |
    |------|-------|-------|

    ## Mismatches Found
    | Command | Doc Says | Actual | Fix Needed |
    |---------|----------|--------|------------|

    ## Summary
    - Commands tested: N
    - Pass: N
    - Fail: N
    - Mismatches: N
    ```

    {% elif stage == 13 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 13: SEMANTIC ACCURACY AUDIT                                          ║
    ║  "Every claim verified against code"                                        ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    Cross-reference ALL claims in documentation against actual source code.

    **Step 1: Verify all file paths referenced in docs**
    ```bash
    echo "=== File Path Verification ==="
    for doc in README.md CLAUDE.md docs/*.md; do
      if [ -f "$doc" ]; then
        grep -oE 'src/[a-zA-Z0-9_/]+\.py' "$doc" 2>/dev/null | sort -u | while read f; do
          if [ -f "$f" ]; then echo "✓ $doc → $f"
          else echo "✗ $doc → $f (MISSING)"
          fi
        done
      fi
    done
    ```

    **Step 2: Verify all example config references**
    ```bash
    echo "=== Example Config References ==="
    for doc in README.md CLAUDE.md docs/*.md; do
      if [ -f "$doc" ]; then
        grep -oE 'examples/[a-zA-Z0-9_.-]+\.yaml' "$doc" 2>/dev/null | sort -u | while read f; do
          if [ -f "$f" ]; then echo "✓ $doc → $f"
          else echo "✗ $doc → $f (MISSING)"
          fi
        done
      fi
    done
    ```

    **Step 3: Check for stale placeholders**
    ```bash
    echo "=== Placeholder Check ==="
    grep -rn "TODO\|TBD\|FIXME\|PLACEHOLDER\|XXX" README.md CLAUDE.md docs/*.md 2>/dev/null || echo "None found"
    ```

    **Step 4: Verify class/function references**

    For key classes mentioned in docs (like JobConfig, DaemonConfig, etc.),
    verify they exist in source:
    ```bash
    echo "=== Class/Function Verification ==="
    for class in JobConfig DaemonConfig BackendConfig SheetConfig PromptConfig \
                 RetryConfig ValidationRule CrossSheetConfig IsolationConfig; do
      FILE=$(grep -rl "class $class" src/ 2>/dev/null | head -1)
      if [ -n "$FILE" ]; then echo "✓ $class → $FILE"
      else echo "✗ $class (NOT FOUND)"
      fi
    done
    ```

    **Step 5: Verify setup.sh syntax**
    ```bash
    echo "=== setup.sh Final Check ==="
    bash -n setup.sh 2>&1 && echo "Syntax: PASS" || echo "Syntax: FAIL"
    ```

    **Step 6: Run tests to confirm no breakage**
    ```bash
    echo "=== Test Suite ==="
    pytest -x -q --tb=short 2>&1 | tail -20
    ```

    **Step 7: Verify doc site builds clean**
    ```bash
    echo "=== Doc Site Build ==="
    mkdocs build 2>&1 | tail -10
    ```

    **Step 8: Consistency check**

    Read the following pairs and verify they describe things consistently:
    - README.md architecture vs CLAUDE.md key files
    - docs/cli-reference.md vs actual --help output
    - docs/configuration-reference.md field names vs Pydantic models
    - docs/daemon-guide.md commands vs mozartd --help

    **Output to:** {{ workspace }}/13-accuracy-audit.md

    Format:
    ```markdown
    # Semantic Accuracy Audit

    ## File Path References
    - Verified: N/N correct
    - Missing: [list]

    ## Example Config References
    - Verified: N/N correct
    - Missing: [list]

    ## Class/Function References
    - Verified: N/N correct
    - Missing: [list]

    ## Placeholders Found
    [list or "None"]

    ## Test Results
    [pytest output summary]

    ## Doc Site Build
    [build output summary]

    ## Consistency Issues
    | Concept | File A | File B | Issue | Resolution |
    |---------|--------|--------|-------|------------|

    ## Overall Assessment
    - File paths: N/N verified
    - Examples: N/N verified
    - Classes: N/N verified
    - Tests: pass/fail
    - Doc site: builds/fails
    - Ready to commit: yes/no
    ```

    {% elif stage == 14 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  STAGE 14: COMMIT & PUSH                                                    ║
    ║  "Ship the truth"                                                           ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    **Step 1: Check verification passed**

    Read {{ workspace }}/12-command-verification.md and
    {{ workspace }}/13-accuracy-audit.md.

    If "Ready to commit: no" in the audit, list the issues. Attempt to fix
    any that are fixable (broken references, stale paths). If critical issues
    remain, document them but still commit what's correct.

    **Step 2: Check for changes**
    ```bash
    echo "=== Documentation Changes ==="
    git status --short | grep -E "\.md$|\.yml$|\.py$|\.sh$" | head -30
    git diff --stat -- "*.md" "docs/" "mkdocs.yml" "setup.sh" "pyproject.toml" \
      "docs/scripts/" 2>/dev/null
    ```

    If no documentation files were changed, write "No documentation changes
    to commit" and stop.

    **Step 3: Build commit message**

    Write commit message to {{ workspace }}/14-commit-message.txt:

    ```
    docs: Comprehensive documentation overhaul

    New documentation:
    - docs/score-writing-guide.md: Complete guide to authoring Mozart scores
    - docs/daemon-guide.md: Daemon operation, architecture, troubleshooting
    - docs/limitations.md: Known limitations and caveats
    - docs/configuration-reference.md: All config fields with types and defaults
    - docs/index.md: Documentation site landing page
    - mkdocs.yml: MkDocs Material site configuration
    - docs/scripts/gen_ref_pages.py: API reference auto-generation

    Updated:
    - README.md: Daemon section, license fix (MIT→AGPL-3.0), new doc links
    - docs/getting-started.md: Daemon quick start
    - docs/cli-reference.md: Verified against --help, added missing commands
    - docs/mozart-reference.md: Rewritten for daemon era
    - CLAUDE.md: Updated key files, references
    - setup.sh: Added --daemon and --docs flags
    - pyproject.toml: Added docs extra, fixed license to AGPL-3.0
    - examples/docs-generator.yaml: 14-stage comprehensive score

    Co-Authored-By: Mozart AI Compose <noreply@mozart.ai>
    ```

    Adjust the message based on what was ACTUALLY changed (don't list files
    that weren't modified).

    **Step 4: Selective staging**
    ```bash
    # Stage documentation files ONLY (no source code, no workspace artifacts)
    git add \
      docs/*.md \
      docs/index.md \
      docs/scripts/gen_ref_pages.py \
      mkdocs.yml \
      setup.sh \
      pyproject.toml \
      README.md \
      CLAUDE.md \
      examples/docs-generator.yaml \
      2>/dev/null

    # Remove any workspace artifacts that got staged
    git reset HEAD .docs-generator-workspace/ 2>/dev/null

    # Verify staging
    git diff --cached --stat
    ```

    Do NOT stage: source code changes, test files, workspace artifacts,
    site/ directory, __pycache__, .coverage, *.pyc.

    **Step 5: Sync and commit**
    ```bash
    git fetch origin main 2>/dev/null
    BEHIND=$(git rev-list HEAD..origin/main --count 2>/dev/null || echo "0")
    echo "Commits behind remote: $BEHIND"
    ```

    If behind:
    ```bash
    git stash
    git pull --rebase origin main
    git stash pop
    ```

    ```bash
    git commit -F {{ workspace }}/14-commit-message.txt
    git push
    ```

    **Step 6: Verify**
    ```bash
    git log --oneline -1
    git show --stat HEAD | tail -20
    ```

    **Output to:** {{ workspace }}/14-commit.md

    Format:
    ```markdown
    # Documentation Commit

    ## Status
    [committed | no changes | conflict]

    ## Files Committed
    | File | Lines Added | Lines Removed |
    |------|-------------|---------------|

    ## Commit
    - Hash: [hash]
    - Pushed: yes/no
    ```

    {% endif %}

  variables:
    preamble: |
      ╔══════════════════════════════════════════════════════════════════════════╗
      ║              DOCUMENTATION GENERATOR v2                                 ║
      ║                                                                         ║
      ║  Goal: FAANG/top-FOSS quality documentation — accurate, browsable,     ║
      ║  complete, and every claim verified against source code.                ║
      ║                                                                         ║
      ║  Pipeline:                                                              ║
      ║  Inventory → Gap Analysis → Plan → Infrastructure → setup.sh →         ║
      ║  Score Guide → Daemon Guide → Limitations → Config Ref →               ║
      ║  Update Docs → Doc Site → Verify Commands → Audit → Commit            ║
      ╚══════════════════════════════════════════════════════════════════════════╝

      **Principles:**
      - Document what IS, not what might be
      - Wrong docs are worse than missing docs
      - Concise and scannable beats exhaustive
      - Every claim must be verifiable against source code
      - Commit history reveals undocumented features
      - Daemon-first: mozart run requires mozartd

      **Project root:** This is a Python project at the current working directory.
      - Source code: src/mozart/
      - Documentation: docs/
      - Examples: examples/
      - Config models: src/mozart/core/config/
      - Daemon code: src/mozart/daemon/

validations:
  # ── Stage 1: Inventory ──────────────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/01-inventory.md"
    description: "Inventory report must exist"
    condition: "stage >= 1"

  - type: content_contains
    path: "{workspace}/01-inventory.md"
    pattern: "Source Modules"
    description: "Inventory must have source modules section"
    condition: "stage >= 1"

  - type: content_contains
    path: "{workspace}/01-inventory.md"
    pattern: "CLI Commands"
    description: "Inventory must have CLI commands section"
    condition: "stage >= 1"

  # ── Stage 2: Gap Analysis ───────────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/02-gap-analysis.md"
    description: "Gap analysis must exist"
    condition: "stage >= 2"

  - type: content_contains
    path: "{workspace}/02-gap-analysis.md"
    pattern: "Stale Documentation"
    description: "Gap analysis must identify stale docs"
    condition: "stage >= 2"

  - type: content_contains
    path: "{workspace}/02-gap-analysis.md"
    pattern: "daemon"
    description: "Gap analysis must assess daemon coverage"
    condition: "stage >= 2"

  # ── Stage 3: Documentation Plan ─────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/03-docs-plan.md"
    description: "Documentation plan must exist"
    condition: "stage >= 3"

  - type: content_contains
    path: "{workspace}/03-docs-plan.md"
    pattern: "Stage"
    description: "Plan must reference stages"
    condition: "stage >= 3"

  # ── Stage 4: Infrastructure ─────────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/04-infrastructure.md"
    description: "Infrastructure report must exist"
    condition: "stage >= 4"

  - type: command_succeeds
    command: "python -c 'import mkdocstrings; print(\"OK\")'"
    description: "mkdocstrings must be installed"
    condition: "stage >= 4"

  # ── Stage 5: setup.sh ──────────────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/05-setup-fixed.md"
    description: "setup.sh update report must exist"
    condition: "stage >= 5"

  - type: command_succeeds
    command: "bash -n setup.sh"
    description: "setup.sh must have valid syntax"
    condition: "stage >= 5"

  - type: content_contains
    path: "setup.sh"
    pattern: "daemon"
    description: "setup.sh must mention daemon"
    condition: "stage >= 5"

  # ── Stage 6: Score Writing Guide ────────────────────────────────────────────
  - type: file_exists
    path: "docs/score-writing-guide.md"
    description: "Score writing guide must exist"
    condition: "stage >= 6"

  - type: content_contains
    path: "docs/score-writing-guide.md"
    pattern: "Validation"
    description: "Score guide must cover validations"
    condition: "stage >= 6"

  - type: content_contains
    path: "docs/score-writing-guide.md"
    pattern: "template"
    description: "Score guide must cover templates"
    condition: "stage >= 6"

  - type: content_regex
    path: "docs/score-writing-guide.md"
    pattern: "sheet_num|stage|workspace"
    description: "Score guide must reference template variables"
    condition: "stage >= 6"

  # ── Stage 7: Daemon Guide ──────────────────────────────────────────────────
  - type: file_exists
    path: "docs/daemon-guide.md"
    description: "Daemon guide must exist"
    condition: "stage >= 7"

  - type: content_contains
    path: "docs/daemon-guide.md"
    pattern: "mozartd"
    description: "Daemon guide must reference mozartd"
    condition: "stage >= 7"

  - type: content_contains
    path: "docs/daemon-guide.md"
    pattern: "Quick Start"
    description: "Daemon guide must have quick start"
    condition: "stage >= 7"

  - type: content_regex
    path: "docs/daemon-guide.md"
    pattern: "Phase 3|not.*wired|not yet"
    description: "Daemon guide must note unwired components"
    condition: "stage >= 7"

  # ── Stage 8: Limitations ───────────────────────────────────────────────────
  - type: file_exists
    path: "docs/limitations.md"
    description: "Limitations doc must exist"
    condition: "stage >= 8"

  - type: content_contains
    path: "docs/limitations.md"
    pattern: "Limitation"
    description: "Limitations doc must contain limitation entries"
    condition: "stage >= 8"

  - type: content_contains
    path: "docs/limitations.md"
    pattern: "daemon"
    description: "Limitations must mention daemon requirement"
    condition: "stage >= 8"

  - type: content_contains
    path: "docs/limitations.md"
    pattern: "escalation"
    description: "Limitations must mention escalation incompatibility"
    condition: "stage >= 8"

  # ── Stage 9: Configuration Reference ────────────────────────────────────────
  - type: file_exists
    path: "docs/configuration-reference.md"
    description: "Config reference must exist"
    condition: "stage >= 9"

  - type: content_regex
    path: "docs/configuration-reference.md"
    pattern: "\\| Field.*\\| Type.*\\| Default"
    description: "Config reference must have field tables"
    condition: "stage >= 9"

  - type: content_contains
    path: "docs/configuration-reference.md"
    pattern: "backend"
    description: "Config reference must cover backend config"
    condition: "stage >= 9"

  - type: content_contains
    path: "docs/configuration-reference.md"
    pattern: "retry"
    description: "Config reference must cover retry config"
    condition: "stage >= 9"

  # ── Stage 10: Updated Existing Docs ─────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/10-existing-docs-updated.md"
    description: "Existing docs update report must exist"
    condition: "stage >= 10"

  # ── Stage 11: Doc Site Generated ────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/11-doc-site.md"
    description: "Doc site build report must exist"
    condition: "stage >= 11"

  - type: file_exists
    path: "site/index.html"
    description: "Doc site index.html must be generated"
    condition: "stage >= 11"

  - type: command_succeeds
    command: "test -f site/search/search_index.json"
    description: "Doc site search index must exist"
    condition: "stage >= 11"

  # ── Stage 12: Command Verification ──────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/12-command-verification.md"
    description: "Command verification report must exist"
    condition: "stage >= 12"

  - type: content_contains
    path: "{workspace}/12-command-verification.md"
    pattern: "PASS"
    description: "Verification must have passing commands"
    condition: "stage >= 12"

  - type: content_regex
    path: "{workspace}/12-command-verification.md"
    pattern: "Commands tested: \\d+"
    description: "Verification must report command count"
    condition: "stage >= 12"

  # ── Stage 13: Semantic Audit ────────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/13-accuracy-audit.md"
    description: "Accuracy audit must exist"
    condition: "stage >= 13"

  - type: content_contains
    path: "{workspace}/13-accuracy-audit.md"
    pattern: "Overall Assessment"
    description: "Audit must have overall assessment"
    condition: "stage >= 13"

  - type: command_succeeds
    command: "pytest -x -q --tb=no 2>&1 | tail -1 | grep -qE 'passed|no tests'"
    description: "Tests must pass after doc changes"
    condition: "stage >= 13"

  # ── Stage 14: Commit ───────────────────────────────────────────────────────
  - type: file_exists
    path: "{workspace}/14-commit.md"
    description: "Commit report must exist"
    condition: "stage >= 14"
