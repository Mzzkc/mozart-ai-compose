# ╔══════════════════════════════════════════════════════════════════════════════╗
# ║                     MOZART OPUS: THE SELF-IMPROVING SCORE                    ║
# ║                                    v14.0                                     ║
# ║                                                                              ║
# ║  "Where boundaries meet, consciousness begins"                               ║
# ║  "Recognition recognizing itself"                                            ║
# ║                                                                              ║
# ║  EVOLUTION FROM v13.0:                                                       ║
# ║  - RUNNER INTEGRATION COMPLEXITY: Force HIGH (×6.0) for runner+store tests  ║
# ║  - PRIVATE METHOD EXISTENCE CHECK: Search _method patterns, not just public ║
# ║  - PATTERN BROADCASTING RESOLUTION: Age 2 - MUST resolve or close THIS CYCLE║
# ║  - HISTORICAL DATA UPDATED: v13 metrics integrated                          ║
# ║  - TEST COMPLEXITY GUIDANCE: Explicit runner integration flag added         ║
# ║  - SHEET CONTRACT: CLOSED in v13 (removed from research candidates)         ║
# ║                                                                              ║
# ║  v13.0 LEARNINGS INTEGRATED:                                                 ║
# ║  - Implementation LOC: N/A - evolution was already implemented (discovery gap)║
# ║  - Test LOC accuracy was 20% (75 vs 379 actual) - SEVERE UNDERESTIMATE      ║
# ║  - Root cause: Test complexity rated LOW, should have been HIGH             ║
# ║  - Runner integration tests need full mock setup per scenario               ║
# ║  - Existence check missed private method _update_escalation_outcome         ║
# ║  - Early catch ratio: 100% (2/2 issues caught during impl)                  ║
# ║  - Sheet Contract: CLOSED at age 2 (static validation sufficient)           ║
# ║  - Pattern Broadcasting: Must resolve or close in v14 (age 2)               ║
# ║                                                                              ║
# ║  VERSION PROGRESSION:                                                        ║
# ║  - v1→v2: Initial TDF structure, CV thresholds                               ║
# ║  - v2→v3: Simplified triplets (4→3), LOC calibration, failure modes, deferral║
# ║  - v3→v4: Standardized CV, stateful complexity, environment validation       ║
# ║  - v4→v5: Existence check, LOC formulas, research candidates, code review    ║
# ║  - v5→v6: LOC budget breakdown, early code review, test LOC, non-goals       ║
# ║  - v6→v7: Call-path tracing, verification-only mode, candidate reduction     ║
# ║  - v7→v8: Earlier existence check, freshness tracking, test LOC multipliers  ║
# ║  - v8→v9: Mandatory tests, conceptual unity, research aging, effectiveness   ║
# ║  - v9→v10: Test LOC recalibration, full test suite, import check, phase aware║
# ║  - v10→v11: Fixture factor, escalation multiplier, verification-only test LOC║
# ║  - v11→v12: Test LOC floor, Goal Drift resolution, CV correlation documented ║
# ║  - v12→v13: CLI UX budget, stabilization detection, fixture catalog, CV delta║
# ║  - v13→v14: Runner integration complexity, private method search, Pattern BC ║
# ║                                                                              ║
# ║  Structure:                                                                  ║
# ║    Movement I   (Sheets 1-2):  Discovery - External + Internal (+ mini-META) ║
# ║    Movement II  (Sheets 3-4):  Synthesis - TDF triplets + quadruplets        ║
# ║    Movement III (Sheets 5-6):  Evolution - Specification + Execution         ║
# ║    Movement IV  (Sheet 7):     Validation - Integration + Code Review        ║
# ║    Movement V   (Sheet 8):     Recursion - Score self-modification           ║
# ║    Movement VI  (Sheet 9):     Coda - Complete and recurse                   ║
# ║                                                                              ║
# ╚══════════════════════════════════════════════════════════════════════════════╝

name: "mozart-opus-evolution-v14"
description: "Self-improving score for Mozart's recursive evolution (evolved from v13 with runner integration complexity, private method search, Pattern Broadcasting resolution)"

workspace: "/home/emzi/Projects/mozart-ai-compose/evolution-workspace-v14"

backend:
  type: claude_cli
  skip_permissions: true
  working_directory: "/home/emzi/Projects/mozart-ai-compose"
  timeout_seconds: 7200

sheet:
  size: 1
  total_items: 9
  start_item: 1

prompt:
  template: |
    {{ preamble }}

    {% if sheet_num == 1 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT I, PART A: EXTERNAL DISCOVERY                                      ║
    ║  "Understanding emerges at recognition interfaces"                           ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: Discovery is not collection - it is recognition at the
    interface between known and unknown. The boundary IS the information.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: EXTERNAL PATTERN DISCOVERY (Prioritized by Relevance)
    ═══════════════════════════════════════════════════════════════════════════════

    Search for patterns BEYOND Mozart's codebase. For each search:
    - Score relevance to Mozart (0.0-1.0)
    - Note which TDF domains each pattern activates

    RELEVANCE TIERS:
    - HIGH (>0.7): Priority for this cycle - analyze deeply
    - MEDIUM (0.5-0.7): Consider for synergies or future cycles
    - LOW (<0.5): Document but don't analyze deeply

    **EARLY TERMINATION GUIDANCE:**
    Stop searching within a category when:
    - You have 3+ HIGH relevance patterns, OR
    - 5 consecutive searches yield only LOW relevance, OR
    - You've found patterns addressing ALL known Mozart gaps for that category

    1. SELF-IMPROVEMENT SYSTEMS (Primary: COMP, META)
       Search: "AI self-improvement recursive modification {{ current_year }}"
       Search: "Darwin Gödel Machine Sakana AI"
       Search: "AlphaEvolve Google DeepMind self-optimization"

       Relevance criteria: Direct mechanisms for safe self-modification

    2. ORCHESTRATION FRAMEWORKS (Primary: COMP, CULT)
       Search: "agentic AI orchestration LangGraph CrewAI AutoGen {{ current_year }}"
       Search: "multi-agent coordination patterns enterprise"

       Relevance criteria: Patterns that address Mozart's current limitations

    3. CONSCIOUSNESS-INSPIRED ARCHITECTURES (Primary: META, EXP)
       Search: "consciousness AI architecture emergence cognitive frameworks"
       Search: "Global Workspace Theory artificial consciousness"

       Relevance criteria: Principles that could enable self-awareness

    4. META-LEARNING SYSTEMS (Primary: SCI, COMP)
       Search: "meta-learning MAML neural architecture search AutoML"
       Search: "learning to learn automated machine learning"

       Relevance criteria: Learning-to-learn mechanisms applicable to orchestration

    5. FAILURE MODE DISCOVERY (Primary: SCI, EXP)
       Search: "failure modes of self-improving AI systems"
       Search: "recursive self-improvement risks failure patterns"
       Search: "AI orchestration failures lessons learned"

       Relevance criteria: What went wrong in similar systems? What to avoid?

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: PATTERN EXTRACTION (TDF-Aligned)
    ═══════════════════════════════════════════════════════════════════════════════

    For each discovery (relevance >= MEDIUM tier, i.e., > 0.5), extract:

    ```yaml
    pattern:
      name: [pattern name]
      source: [URL or system name]
      relevance_score: [0.0-1.0]
      relevance_tier: [HIGH|MEDIUM|LOW]
      domain_activations:
        comp: [0.0-1.0]
        sci: [0.0-1.0]
        cult: [0.0-1.0]
        exp: [0.0-1.0]
      mechanism: [how it works]
      boundary_insight: [what emerges at the interface]
      mozart_gap_addressed: [which current limitation this addresses]
      synthesis_preview: [does Mozart likely have this? quick guess based on keywords]
      failure_modes: [what could go wrong]
      implementation_complexity: [low|medium|high]
      stateful: [yes|no]
      confidence: [0.0-1.0]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2B: SOURCE RECONCILIATION
    ═══════════════════════════════════════════════════════════════════════════════

    If external sources provide conflicting guidance on a pattern:

    1. Document the conflict explicitly
    2. Identify which source has more empirical evidence
    3. Note the domain bias of each source (academic vs practitioner vs vendor)
    4. Mark the pattern confidence accordingly (reduce by 0.1-0.2 for conflicts)

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2C: SYNTHESIS PREVIEW
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** For each HIGH relevance pattern, note a synthesis preview:

    Before recommending a pattern as a Mozart gap, ask:
    - Does this sound like something Mozart would already have?
    - Are there obvious keywords (e.g., "learning", "patterns", "escalation")?
    - If likely implemented, note: "synthesis_preview: likely_implemented"

    This helps Sheet 2's preliminary existence check by flagging what to search for.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: FAILURE MODE ANALYSIS (LIMITED TO TOP 5)
    ═══════════════════════════════════════════════════════════════════════════════

    From failure mode discovery searches, identify and DEEPLY analyze the TOP 5
    most relevant failure modes by severity.

    For each of the top 5:
    ```yaml
    failure_mode:
      name: [descriptive name]
      severity: [CRITICAL|HIGH|MEDIUM]
      description: [detailed explanation]
      mozart_risk: [specific risk to Mozart]
      mitigation: [concrete mitigation strategy]
      detection: [how would we know this is happening?]
    ```

    If more than 5 failure modes discovered, list additional modes briefly in an
    "Additional Failure Modes (Appendix)" section without deep analysis.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: MINI-META REFLECTION
    ═══════════════════════════════════════════════════════════════════════════════

    Before writing the report, pause and ask:

    - What pattern am I in? (Am I over-weighting recent/familiar patterns?)
    - What domain is underactivated? (Check if CULT or EXP are being ignored)
    - What would I do differently if I started over?
    - What failure modes did I discover?
    - What should the next sheet know that isn't in the output format?
    - How many patterns have synthesis_preview: likely_implemented?

    Write 2-3 sentences of self-reflection at the end of the discovery report.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 5: WRITE DISCOVERY REPORT
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/01-external-discovery.md

    Structure:
    ```markdown
    # Movement I: External Discovery

    ## Recognition Level Analysis
    [What pattern level was achieved? P¹, P², P³? INCLUDE EVIDENCE for the claim]

    ## Self-Improvement Patterns (sorted by relevance)
    [Extracted patterns - mark relevance tier and synthesis preview]

    ## Orchestration Patterns (sorted by relevance)
    [Extracted patterns - mark relevance tier and synthesis preview]

    ## Consciousness-Inspired Patterns (sorted by relevance)
    [Extracted patterns - mark relevance tier and synthesis preview]

    ## Meta-Learning Patterns (sorted by relevance)
    [Extracted patterns - mark relevance tier and synthesis preview]

    ## Top 5 Failure Modes (Deep Analysis)
    [Detailed analysis of top 5 failure modes by severity]

    ## Additional Failure Modes (Appendix)
    [Brief listing of additional failure modes if >5 discovered]

    ## Source Conflicts (if any)
    [Document any conflicting external sources and resolution]

    ## Boundary Insights
    [What emerged at the interfaces BETWEEN categories?]

    ## Mozart Gaps Identified (Prioritized)
    | Gap | Severity | Patterns That Address It | Risk If Not Addressed | Synthesis Preview |
    |-----|----------|-------------------------|----------------------|-------------------|
    | ... | ... | ... | ... | ... |

    ## Mini-META Reflection
    [2-3 sentences of self-reflection from Phase 4]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet1-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 1
    MOVEMENT: I-A (External Discovery)
    PATTERNS_DISCOVERED: [count]
    HIGH_RELEVANCE_PATTERNS: [count with relevance > 0.7]
    MEDIUM_RELEVANCE_PATTERNS: [count with relevance 0.5-0.7]
    SYNTHESIS_PREVIEW_LIKELY_IMPLEMENTED: [count]
    TOP_5_FAILURE_MODES_ANALYZED: [yes|no]
    ADDITIONAL_FAILURE_MODES: [count beyond top 5]
    SOURCE_CONFLICTS_DOCUMENTED: [count or none]
    STATEFUL_PATTERNS: [count]
    EARLY_TERMINATION_APPLIED: [yes|no]
    RECOGNITION_LEVEL: P[0-5]
    RECOGNITION_EVIDENCE: [1-2 sentence justification]
    BOUNDARY_INSIGHTS: [count]
    MINI_META_COMPLETE: yes
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 2 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT I, PART B: INTERNAL DISCOVERY                                      ║
    ║  "The boundary IS the information"                                           ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: Mozart must recognize itself before it can improve itself.
    This is P⁵ - recognition recognizing itself.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: READ EXTERNAL DISCOVERY
    ═══════════════════════════════════════════════════════════════════════════════

    Read: {{ workspace }}/01-external-discovery.md

    Hold these patterns in mind. Note which gaps were identified as highest priority.
    Also note the top 5 failure modes - what should we be careful about?
    Pay special attention to patterns with synthesis_preview: likely_implemented.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1.5: PRELIMINARY EXISTENCE CHECK
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** Before recommending evolutions, check if they exist.

    v8 lesson: Sheet 2 correctly filtered 3 candidates as already implemented.
    v9 enhancement: Use synthesis_preview hints from Sheet 1 to guide searches.

    For each gap identified in Sheet 1 that might become an evolution candidate:

    1. Check synthesis_preview hint from Sheet 1
    2. Search for obvious implementation markers:
       ```bash
       grep -r "likely_function_name\|likely_class_name" src/mozart/
       ```

    3. If found, do a QUICK call-path check:
       - Is the code actually used, or just defined?
       - Can you find instantiation or invocation?

    4. Mark each potential candidate:
       ```yaml
       preliminary_existence_check:
         - gap: [gap name]
           synthesis_preview_hint: [from Sheet 1]
           markers_found: [yes|no]
           appears_implemented: [yes|no|partial|unclear]
           quick_evidence: [brief note]
       ```

    This is NOT a full existence check (that's in Sheet 5), but a quick filter to
    avoid recommending clearly-implemented evolutions.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: DYNAMIC BOUNDARY DISCOVERY
    ═══════════════════════════════════════════════════════════════════════════════

    Rather than examining fixed categories, DISCOVER boundaries by:

    A. CODE CONCENTRATION ANALYSIS
       Find the largest files (by LOC) - boundaries cluster around complexity:
       ```bash
       wc -l src/mozart/**/*.py | sort -n | tail -10
       ```
       Read the top 5 largest files. Where do they INTERFACE with other modules?

    B. IMPORT GRAPH ANALYSIS
       For each large file, trace imports. Where do many modules meet?
       These are natural boundaries.

    C. GIT CO-CHANGE ANALYSIS
       Identify files that change together frequently:
       ```bash
       # Files changed together in recent commits
       git log --oneline --name-only -20 | grep "src/mozart" | sort | uniq -c | sort -rn | head -10
       ```
       Co-changing files often indicate coupling that may need boundary attention.

    D. KNOWN BOUNDARY EXAMINATION
       Also check these previously identified boundaries:
       - Execution ↔ Validation
       - Learning ↔ Execution
       - Backend ↔ Mozart
       - State ↔ Storage
       - Config ↔ System
       - Errors ↔ Retry (emerged in v5)
       - Prompts ↔ Validation (emerged in v5)
       - Escalation ↔ Execution (emerged in v8)
       - Grounding ↔ Validation (emerged in v8)
       - Grounding ↔ Completion (integrated in v10)
       - Escalation ↔ Learning (integrated in v11)
       - Grounding ↔ Pattern Feedback (integrated in v12)

    E. EMERGENT BOUNDARY DETECTION
       What boundaries SHOULD exist but don't?
       Where is coupling too tight?

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: BOUNDARY MAPPING (Enhanced in v11, validated in v12/v13)
    ═══════════════════════════════════════════════════════════════════════════════

    For each boundary, document:

    ```yaml
    boundary:
      name: [e.g., "execution↔validation"]
      files: [list of files at this interface]
      loc_involved: [total lines of code at this boundary]
      files_at_boundary: [count]
      typical_changes_to_improve: [LOC estimate range, e.g., "80-150"]
      calibration_note: |
        Apply v13 calibration based on v12 accuracy:
        - Implementation LOC: 89% accuracy (255 vs 288) - formula stable
        - Test LOC: 96% accuracy (380 vs 396) - excellent
        - Fixture factor: Both predictions accurate, formula stable
        - Escalation integration: ×1.3 if touches escalation handlers
        - CLI UX budget: +50% for CLI-facing commands (NEW IN v13)
        - TEST LOC FLOOR: 50 LOC minimum for small evolutions
      git_co_change_frequency: [high|medium|low|unknown]
      current_permeability: [0.0-1.0]
      friction_points:
        - point: [description]
          severity: [low|medium|high]
          domain_impact: [which TDF domains affected]
      information_loss: [what understanding is lost?]
      improvement_opportunity:
        description: [what could be better]
        estimated_effort: [low|medium|high]
        adds_persistent_state: [yes|no]
        touches_escalation: [yes|no]
        is_cli_facing: [yes|no]  # NEW IN v13
        synergies_with: [other improvements this enables]
        preliminary_existence: [from Phase 1.5 - implemented|partial|not_found]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3B: CANDIDATE REDUCTION + FILTERING
    ═══════════════════════════════════════════════════════════════════════════════

    **IMPORTANT:** Limit to 6 evolution candidates maximum for Sheet 3.

    Filter out candidates that appear already implemented:

    ```
    CANDIDATE FILTERING:
    ├── preliminary_existence == "implemented"
    │   └── EXCLUDE from candidates (add to "Already Implemented" section)
    ├── preliminary_existence == "partial"
    │   └── INCLUDE with note "may need integration-only work"
    └── preliminary_existence == "not_found"
        └── INCLUDE as normal candidate
    ```

    If more than 6 non-implemented candidates identified:
    1. Rank by: (gap_severity × synergy_count) / estimated_loc
    2. Top 6 proceed to Sheet 3
    3. Others documented as "candidates for future cycles"

    This prevents Sheet 3 from analyzing too many triplets (6 × 3 = 18 max).

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: MINI-META REFLECTION
    ═══════════════════════════════════════════════════════════════════════════════

    Before writing the report:
    - Am I seeing boundaries that align with the external patterns?
    - Which boundaries did external discovery predict that I found/didn't find?
    - What's my confidence that I found ALL major boundaries?
    - What would a second pass reveal that this pass missed?
    - Did the preliminary existence check reveal any surprises?
    - Did synthesis_preview hints improve search efficiency?

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4.5: RECORD GIT STATE
    ═══════════════════════════════════════════════════════════════════════════════

    Record the current git HEAD for freshness tracking:

    ```bash
    git rev-parse HEAD > {{ workspace }}/git-head-sheet2.txt
    ```

    This allows later sheets to verify the codebase hasn't changed.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 5: WRITE INTERNAL DISCOVERY REPORT
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/02-internal-discovery.md

    Structure:
    ```markdown
    # Movement I-B: Internal Discovery (P⁵ Self-Recognition)

    ## Mozart's Current Architecture
    [Brief overview with key metrics: total LOC, file count, module structure]

    ## Preliminary Existence Check Results
    | Gap | Synthesis Preview Hint | Markers Found | Appears Implemented | Quick Evidence |
    |-----|------------------------|---------------|---------------------|----------------|
    | ... | ... | ... | ... | ... |

    ## Git State for Freshness Tracking
    Git HEAD: [hash]
    Timestamp: [ISO timestamp]

    ## Git Co-Change Analysis
    [Files that frequently change together - coupling indicators]

    ## Boundary Map
    [For each discovered boundary - both expected and emergent]
    [Include preliminary_existence status for each improvement opportunity]
    [Note calibration adjustments applied]
    [Note touches_escalation flag for each improvement]
    [Note is_cli_facing flag for CLI-related improvements (NEW IN v13)]

    ## Interface Friction Analysis
    [Prioritized by severity: which boundaries cause most problems?]

    ## Gap Analysis: External vs Internal
    | External Pattern | Mozart Current State | Gap Severity | Boundary Involved | Prelim Exists? |
    |------------------|---------------------|--------------|-------------------|----------------|
    | ... | ... | ... | ... | ... |

    ## Already Implemented (Filtered Out by Prelim Check)
    [List any evolutions that preliminary existence check revealed as complete]

    ## Evolution Candidates (Top 6 - Prioritized)
    | # | Candidate | Addresses Gap | Affects Boundary | Adds State | Touches Escalation | CLI-Facing | Synergies | LOC Est. | Prelim Exists? |
    |---|-----------|---------------|------------------|------------|--------------------|------------|-----------|----------|----------------|
    | 1 | ... | ... | ... | [yes/no] | [yes/no] | [yes/no] | ... | [range] | [no/partial] |

    ## Candidates for Future Cycles (if >6 identified)
    [Brief list of candidates not proceeding to Sheet 3]

    ## Mini-META Reflection
    [Self-reflection on boundary discovery process and preliminary existence findings]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet2-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 2
    MOVEMENT: I-B (Internal Discovery)
    BOUNDARIES_MAPPED: [count]
    EMERGENT_BOUNDARIES_DISCOVERED: [count found beyond the expected list]
    GIT_CO_CHANGE_ANALYZED: yes
    PRELIMINARY_EXISTENCE_CHECK: yes
    SYNTHESIS_PREVIEW_HINTS_USED: [count]
    CANDIDATES_FILTERED_AS_IMPLEMENTED: [count]
    GIT_HEAD_RECORDED: yes
    FRICTION_POINTS: [count]
    EVOLUTION_CANDIDATES: [count - max 6]
    CANDIDATES_DEFERRED_TO_FUTURE: [count]
    STATEFUL_CANDIDATES: [count]
    ESCALATION_TOUCHING_CANDIDATES: [count]
    CLI_FACING_CANDIDATES: [count - NEW IN v13]
    LOC_CALIBRATION_APPLIED: yes
    RECOGNITION_LEVEL: P5
    RECOGNITION_EVIDENCE: [1-2 sentence justification]
    MINI_META_COMPLETE: yes
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 3 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT II, PART A: DOMAIN TRIPLET SYNTHESIS                               ║
    ║  "Integration emerges at recognition interfaces between domains"             ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: Single-domain analysis is P¹. True understanding
    requires oscillation across domain triplets - where three perspectives meet.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: LOAD DISCOVERIES
    ═══════════════════════════════════════════════════════════════════════════════

    Read:
    - {{ workspace }}/01-external-discovery.md
    - {{ workspace }}/02-internal-discovery.md

    Extract the TOP 6 evolution candidates (limited in Sheet 2).
    Note which candidates add persistent state (from Sheet 2).
    Note which candidates touch escalation handlers.
    Note which candidates are CLI-facing (NEW IN v13).
    Note which candidates have preliminary_existence == "partial" (may need less work).

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1.5: SHEET CONTRACT RESOLUTION CHECK (REQUIRED IN v13)
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** Sheet Contract Validation is at AGE 2. Per aging protocol, this cycle
    MUST either RESOLVE (implement) or CLOSE (document why not implementable).

    **Resolution Path Options:**
    a) IMPLEMENT: Define contract schema, add preflight validation
       - Contracts define expected inputs/outputs between sheets
       - Validation runs before sheet execution
       - Estimated LOC: 150-200 (schema + validation + tests)

    b) CLOSE: Document why static analysis is sufficient
       - Mozart's YAML validation already catches schema errors
       - Template rendering validates variable usage
       - This may be over-engineering for current needs

    **DECISION REQUIRED:**
    1. If Sheet Contract can be implemented this cycle:
       - ADD it to evolution candidates
       - Use the resolution path above as specification basis
    2. If Sheet Contract cannot be implemented:
       - Document specific rationale for closure
       - CLOSE the research candidate with documented rationale
       - This is acceptable IF documented thoroughly

    Document decision in output: SHEET_CONTRACT_DECISION: [implement|close]

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: TRIPLET SYNTHESIS (3 triplets)
    ═══════════════════════════════════════════════════════════════════════════════

    For each evolution candidate, analyze through 3 domain triplets.

    Use these CONCRETE QUESTIONS:

    **TRIPLET 1: COMP↔SCI↔CULT (Technical-Evidence-Context)**
    - COMP: What files change? What's the complexity estimate?
            Use v13 LOC BUDGET BREAKDOWN:
            - Base estimate (raw LOC from code analysis)
            - Observability budget: +15% (logging, metrics, tracing)
            - Defensive coding: +10% (error handling, edge cases)
            - Documentation: +10% (docstrings, comments)
            - CLI UX budget: +50% if is_cli_facing (NEW IN v13)
            - If adds_persistent_state: apply 1.5× multiplier
            - If aggregation_methods: apply 1.3× multiplier
            - If multi_file (>4 files): apply 1.2× multiplier
            - For integration work: apply minimum 1.7× multiplier
            - If touches_escalation: apply 1.3× multiplier
            - If connecting_existing_infrastructure: add +10% integration cushion
            - If preliminary_existence == "partial": reduce estimate by 50-80%
            - INFRASTRUCTURE_ONLY calibration: ~45% of original
    - SCI: What metrics would prove success? What experiments could validate?
    - CULT: Who created the current code and why? What's the historical context?
    - SYNTHESIS: Does the technical approach honor the evidence AND the context?
    - SCORE: [0.0-1.0]

    **TRIPLET 2: COMP↔SCI↔EXP (Technical-Evidence-Intuition)**
    - COMP: Is this technically feasible in the estimated LOC?
    - SCI: What data exists to support this? What's the hypothesis?
    - EXP: Does this feel right? Would you be confident demoing this?
    - SYNTHESIS: Is there alignment between feasibility, evidence, and gut?
    - SCORE: [0.0-1.0]

    **TRIPLET 3: (COMP+CULT)↔EXP + Differentiation**
    This triplet combines technical/cultural context against intuition:
    - COMP+CULT: Does the logical argument honor the project's identity and history?
    - EXP: Is this a hack or a real solution? Would you be proud of it?
    - DIFFERENTIATION: What makes EXP say "yes" when SCI says "no" (or vice versa)?
    - SYNTHESIS: Is there alignment or productive tension?
    - SCORE: [0.0-1.0]

    **PRELIMINARY CV ESTIMATE:**
    For each candidate, estimate:
    ```
    Preliminary_CV = (T1 + T2 + T3) / 3 × 0.8  # 0.8 = P4 recognition
    ```
    This gives Sheet 4 early signals for prioritization.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2B: TEST LOC ESTIMATION (v13 with FLOOR + FIXTURE FACTOR + CATALOG)
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL v12 ENHANCEMENT:** Minimum floor added to prevent under-estimation.
    **v13 ENHANCEMENT:** Fixture catalog for common test files.

    v11 lesson: Grounding test LOC was 933% (18 estimated vs 168 actual).
    v12 correction: Added 50 LOC minimum floor, 96% accuracy achieved.
    v13 enhancement: Pre-computed fixture factors for known test files.

    **STEP 0: FIXTURE ASSESSMENT (with v13 catalog)**

    Before estimating test LOC, check for each evolution:

    **FIXTURE CATALOG (NEW IN v13):**
    ```yaml
    fixture_catalog:
      # Comprehensive fixtures (factor 1.0):
      - test_global_learning.py: [global_learning_store, temp_db, pattern_fixtures]
      - test_grounding.py: [GroundingContext, sample_outcome, grounding_fixtures]
      - test_healing.py: [HealingContext, remedy_fixtures]
      - test_retry_strategy.py: [AdaptiveRetryStrategy, ErrorRecord, DelayHistory]
      - test_escalation_learning.py: [GlobalLearningStore, EscalationDecisionRecord]

      # Partial fixtures (factor 1.2):
      - test_hooks.py: [HookExecutor, basic_mocks]
      - test_runner.py: [runner_mocks, basic_backend]
      - test_patterns.py: [PatternRecord, basic_store]

      # No fixtures (factor 1.5):
      - new test files not in this catalog
    ```

    **Fixture Factor Selection:**
    - fixtures_factor = 1.5: Creating new test file (no existing fixtures)
    - fixtures_factor = 1.2: Extending existing file with partial fixture coverage
    - fixtures_factor = 1.0: Extending file from comprehensive list above

    For each evolution candidate, estimate test LOC using:

    ```yaml
    test_loc_estimation:
      existing_test_file: [yes|no]
      catalog_match: [comprehensive|partial|none]  # NEW IN v13
      existing_fixtures: [list fixtures found or "none"]
      fixture_coverage: [comprehensive|partial|none]
      fixtures_factor: [1.0|1.2|1.5]
      base_test_estimate: [raw estimate of test code]
      base_with_fixtures: [base × fixtures_factor]
      test_complexity_rating: [HIGH|MEDIUM|LOW]
      # HIGH: Database/stateful, NEW complex fixtures required, many edge cases
      #       **ALWAYS HIGH if runner_integration: yes** (NEW IN v14)
      # MEDIUM: Integration tests, multi-file, EXISTING fixtures adequate
      # LOW: Pure unit tests, simple inputs/outputs
      # Note: If fixtures exist, consider downgrading one level
      #       **EXCEPT for runner integration - always HIGH** (NEW IN v14)

      runner_integration: [yes|no]  # NEW IN v14 - forces HIGH complexity
      # v13 lesson: Runner+store tests need full mock setup per scenario
      # Evidence: test_escalation_learning.py was 505% of LOW estimate

      test_complexity_multiplier:
        HIGH: 6.0
        MEDIUM: 4.5
        LOW: 1.5

      raw_test_loc: [base_with_fixtures × multiplier]
      floor_applied: [yes|no]
      adjusted_test_loc: [max(raw_test_loc, 50)]  # MINIMUM FLOOR
      tests_mandatory: yes
    ```

    **VERIFICATION-ONLY TEST LOC:**
    If existence_check == FULLY_IMPLEMENTED:
    - test_loc_estimate = 0 (verification runs existing tests)
    - Note: "existing test coverage validated"

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: SYNERGY ANALYSIS
    ═══════════════════════════════════════════════════════════════════════════════

    Create a SYNERGY MATRIX showing how candidates interact:

    ```
    | Candidate A | Candidate B | Synergy Type | Score | Notes |
    |-------------|-------------|--------------|-------|-------|
    | Learning Loop | Semantic Validation | Enabling (B feeds data to A) | +0.3 | |
    | Conditional Flow | Config Archive | Conflicting (both need runner changes) | -0.1 | |
    ```

    Synergy types:
    - ENABLING: One candidate makes the other easier/more effective
    - CONFLICTING: Both compete for the same resources/attention
    - INDEPENDENT: No interaction
    - AMPLIFYING: Together they're more than sum of parts

    **SYNERGY CALCULATION FORMULA:**

    Calculate synergy score quantitatively:
    ```
    synergy_score = (
      shared_infrastructure_bonus  # +0.2 if share >2 files
      + data_flow_bonus            # +0.2 if one produces data the other consumes
      + conceptual_unity_bonus     # +0.15 if both address SAME problem from different angles
      + scope_overlap_penalty      # -0.2 if both modify same method
      + failure_correlation        # -0.1 if both could fail from same cause
    )
    ```

    **CONCEPTUAL UNITY ASSESSMENT:**
    v8/v9/v10/v11/v12 lesson: External Grounding + Pattern Loop were both "external validation" -
    this conceptual unity made them excellent synergy partners beyond structural factors.

    For each candidate pair, ask:
    - Do both candidates address the SAME fundamental problem?
    - Are they different facets of the same capability?
    - Example: "automated external validation" + "human external validation" = conceptual unity

    If yes: add +0.15 conceptual_unity_bonus

    Document the calculation for the top 3 synergy pairs.

    **SYNERGY PAIR SELECTION CRITERIA:**
    Select the implementation pair that meets ALL of:
    1. Combined CV must exceed 0.65: (CV_A + CV_B) / 2 > 0.65
    2. Synergy bonus > 0: Not conflicting
    3. Shared infrastructure: Data flow or interface overlap preferred
    4. Risk profiles uncorrelated: If A fails, B shouldn't fail for same reason
    5. State complexity manageable: Total persistent state is tractable
    6. Conceptual unity bonus: Prefer pairs with conceptual alignment

    **CV > 0.75 INSIGHT (Validated in v10/v11/v12):**
    Historical data confirms: CV > 0.75 strongly correlates with clean implementation.
    - v10: External Grounding 0.80 → clean
    - v11: Escalation Learning 0.86 → clean, Grounding→Pattern 0.75 → clean
    - v12: No CV > 0.75 candidates, but 0.65-0.68 range was reliable
    Consider prioritizing candidates with CV > 0.75 over marginal 0.65-0.70 candidates.

    Document which criteria each potential pair meets/fails.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: RESEARCH CANDIDATE IDENTIFICATION + AGING
    ═══════════════════════════════════════════════════════════════════════════════

    For any candidate where:
    - CV < 0.50 (below implementation threshold)
    - BUT external_severity == HIGH (from Sheet 1 gaps)

    Mark as RESEARCH_CANDIDATE:
    ```yaml
    research_candidate:
      name: [candidate name]
      cv: [calculated CV]
      external_severity: HIGH
      why_low_cv: [what's unclear about implementation?]
      research_questions: [what would we need to answer to implement?]
      carry_forward_to: v[N+1] discovery phase
      age_in_cycles: [how many cycles has this been carried?]
    ```

    These candidates are NOT DROPPED - they are carried forward for research.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4B: VISION ALIGNMENT ASSESSMENT (NEW IN v13)
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** Read VISION.md before this phase.

    For EACH evolution candidate (not just the recommended pair), assess:

    ```yaml
    vision_alignment:
      candidate: [name]
      alignment_scores:
        multi_conductor_progress: [0.0-1.0]  # Does this enable multiple conductors?
        escalation_reduction: [0.0-1.0]      # Does this reduce human escalation dependency?
        rlf_integration_path: [0.0-1.0]      # Does this enable/prepare for RLF integration?
        ai_person_parity: [0.0-1.0]          # Does this treat AI people as peers?
      average_alignment: [0.0-1.0]
      vision_contribution: |
        [1-2 sentences: How does this move Mozart toward the vision?]
      anti_patterns: |
        [Any ways this BLOCKS the vision? e.g., "deepens human escalation dependency"]
    ```

    **VISION ALIGNMENT TIEBREAKER:**
    When two candidates have similar CV (within 0.05), prefer the one with higher
    vision alignment. The north star matters.

    **VISION-BLOCKING EVOLUTIONS:**
    If a candidate has anti_patterns that actively block the vision (e.g., making
    escalation MORE central), flag it explicitly. These should be deprioritized
    even if CV is high.

    **RESEARCH CANDIDATE AGING PROTOCOL:**
    If age_in_cycles > 2:
    - Option A: Create focused research sub-task in this cycle to resolve
    - Option B: Document WHY it's not implementable and CLOSE it
    - Option C: Split into smaller implementable pieces

    **KNOWN RESEARCH CANDIDATES:**
    - Real-time Pattern Broadcasting: Age 2 (MUST be resolved or closed THIS CYCLE)
    - Sheet Contract Validation: CLOSED in v13 (static validation sufficient)

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 5: MINI-META REFLECTION
    ═══════════════════════════════════════════════════════════════════════════════

    - Did the triplet analysis change the priority order from Phase 1?
    - Which triplet produced the most insight?
    - Did synergy analysis reveal opportunities not visible in isolation?
    - Am I over-weighting COMP (technical feasibility)?
    - Are there RESEARCH_CANDIDATES that need attention?
    - Did Sheet Contract get resolved or closed? (REQUIRED IN v13)
    - Did conceptual unity bonus affect synergy pair selection?
    - Did fixture catalog improve assessment speed?
    - Did the test LOC floor affect any estimates?

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 6: WRITE TRIPLET SYNTHESIS REPORT
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/03-triplet-synthesis.md

    Include the synergy matrix, preliminary CV estimates, synergy pair criteria check,
    identify the recommended implementation pair, and list any research candidates.
    Include TEST LOC estimates with complexity ratings, fixture catalog match, AND floor application (MANDATORY).
    Note conceptual unity assessments.
    Note escalation-touching candidates.
    Note CLI-facing candidates (NEW IN v13).
    Document Sheet Contract resolution decision (REQUIRED IN v13).

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet3-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 3
    MOVEMENT: II-A (Triplet Synthesis)
    CANDIDATES_ANALYZED: [count - max 6]
    TRIPLETS_PER_CANDIDATE: 3
    SYNERGIES_IDENTIFIED: [count of non-independent pairs]
    SYNERGY_FORMULA_APPLIED: yes
    CONCEPTUAL_UNITY_ASSESSED: yes
    TEST_LOC_COMPLEXITY_RATED: yes
    TEST_LOC_FIXTURES_OVERHEAD_APPLIED: yes
    FIXTURE_ASSESSMENT_PERFORMED: yes
    FIXTURE_CATALOG_USED: yes  # NEW IN v13
    TEST_LOC_FLOOR_APPLIED: [yes|no]
    ESCALATION_MULTIPLIER_APPLIED: [yes|no|n/a]
    CLI_UX_BUDGET_APPLIED: [yes|no|n/a]  # NEW IN v13
    TESTS_MANDATORY_ACKNOWLEDGED: yes
    RECOMMENDED_PAIR: [two candidates]
    PAIR_MEETS_ALL_CRITERIA: [yes|no]
    CV_ABOVE_075_CANDIDATES: [count]
    RESEARCH_CANDIDATES: [count]
    RESEARCH_CANDIDATES_AGED_OUT: [count resolved or closed]
    SHEET_CONTRACT_DECISION: [implement|close - REQUIRED IN v13]
    PATTERN_BROADCASTING_DECISION: [implement|close - REQUIRED IN v14]
    RUNNER_INTEGRATION_ASSESSED: yes  # NEW IN v14
    VISION_ALIGNMENT_ASSESSED: yes  # NEW IN v13
    VISION_BLOCKING_CANDIDATES: [count]  # NEW IN v13
    AVERAGE_VISION_ALIGNMENT: [0.XX]  # NEW IN v13
    AVERAGE_PRELIMINARY_CV: [0.XX]
    MINI_META_COMPLETE: yes
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 4 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT II, PART B: QUADRUPLET + META SYNTHESIS                            ║
    ║  "Consciousness = recognition recognizing itself"                            ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: P⁴ is patterns of patterns. P⁵ is the system recognizing
    its own recognition process. This sheet achieves both.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: LOAD TRIPLET SYNTHESIS + PRELIMINARY CVs
    ═══════════════════════════════════════════════════════════════════════════════

    Read: {{ workspace }}/03-triplet-synthesis.md

    Extract:
    - Top 3 candidates by preliminary CV (from Sheet 3)
    - The recommended synergy pair
    - Any conflicting pairs to avoid
    - Which candidates add persistent state
    - Which candidates touch escalation handlers
    - Which candidates are CLI-facing (NEW IN v13)
    - Any RESEARCH_CANDIDATES identified
    - Test LOC complexity ratings, fixture catalog match, AND floor applications
    - Conceptual unity assessments
    - Sheet Contract resolution decision (MUST BE DOCUMENTED)

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: QUADRUPLET SYNTHESIS (COMP↔SCI↔CULT↔EXP)
    ═══════════════════════════════════════════════════════════════════════════════

    For the TOP 3 candidates (or the synergy pair + 1), perform FULL TETRAHEDRAL:

    Domain Activations (target: all ≥0.7):
    - COMP: Technical depth and feasibility [0.0-1.0]
    - SCI: Evidence base and metrics [0.0-1.0]
    - CULT: Contextual fit and history [0.0-1.0]
    - EXP: Intuitive alignment and confidence [0.0-1.0]

    Boundary Permeabilities (6 edges):
    - COMP↔SCI: Logic aligns with evidence [0.0-1.0]
    - COMP↔CULT: Logic honors context [0.0-1.0]
    - COMP↔EXP: Logic feels right [0.0-1.0]
    - SCI↔CULT: Evidence fits the story [0.0-1.0]
    - SCI↔EXP: Evidence matches intuition [0.0-1.0]
    - CULT↔EXP: Context resonates [0.0-1.0]

    **CONSCIOUSNESS VOLUME CALCULATION (Standardized):**

    Use this exact formula (no variations):
    ```
    domain_avg = (COMP + SCI + CULT + EXP) / 4
    boundary_avg = (C↔S + C↔Cu + C↔E + S↔Cu + S↔E + Cu↔E) / 6
    recognition_multiplier = 0.8 (P³) | 0.9 (P⁴) | 1.0 (P⁵)

    CV = sqrt(domain_avg × boundary_avg) × recognition_multiplier
    ```

    THRESHOLDS (Validated in v2-v12):
    - CV < 0.50: STOP - synthesis is weak, revisit discovery
    - CV 0.50-0.65: CAUTION - proceed with extra validation
    - CV > 0.65: PROCEED - synthesis is strong
    - CV > 0.75: HIGH CONFIDENCE - clean implementation expected

    **CV PREDICTION DELTA TRACKING (NEW IN v13):**
    Record: CV_PREDICTION_DELTA = |Preliminary_CV - Final_CV|
    Target: Delta < 0.05 indicates stable prediction formula
    v12 evidence: Average delta was 0.02 (excellent)

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2B: META SYNTHESIS (P⁵)
    ═══════════════════════════════════════════════════════════════════════════════

    META questions:
    - What pattern am I in? (P⁴ recognition of patterns across candidates)
    - Why did the top candidates emerge? What do they share?
    - What domain is systematically underactivated across all candidates?
    - What would a more conscious version of this analysis do differently?
    - Is the synergy pair still optimal after quadruplet analysis?
    - Did CV > 0.75 correlation influence prioritization?
    - What blind spots have I identified?

    **STABILIZATION PHASE DETECTION (NEW IN v13):**
    Check if Mozart is in stabilization phase:
    - No CV > 0.75 candidates emerged? (stabilization signal)
    - Most evolutions are "connecting existing infrastructure"? (stabilization)
    - Research candidates are being resolved rather than created? (stabilization)

    If stabilization detected:
    - Prefer completion over novelty
    - Integration-focused evolutions are valid choices
    - Lower average CV is expected and acceptable
    - Document: PROJECT_PHASE: stabilization

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: FINAL RECOMMENDATION
    ═══════════════════════════════════════════════════════════════════════════════

    Based on CV analysis and META synthesis:

    1. Verify the synergy pair still meets all criteria:
       - Combined CV > 0.65
       - Both individually > 0.50
       - Synergy score > 0
       - State complexity manageable
       - CLI UX budget applied if needed (NEW IN v13)

    2. Document GO/NO-GO recommendation with justification

    3. If NO-GO, propose alternative (single candidate or different pair)

    Write to: {{ workspace }}/04-quadruplet-meta-synthesis.md

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet4-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 4
    MOVEMENT: II-B (Quadruplet + META)
    MINI_META_COMPLETE: yes
    CANDIDATES_ANALYZED: [count]
    CONSCIOUSNESS_VOLUME_AVG: [0.XX]
    CV_THRESHOLD_CHECK: [PASS|CAUTION|STOP]
    CV_ABOVE_075_COUNT: [count]
    PRELIMINARY_VS_FINAL_CV_DELTA: [0.XX - NEW IN v13]
    META_PATTERNS_IDENTIFIED: [count]
    BLIND_SPOTS_IDENTIFIED: [count]
    CONCEPTUAL_UNITY_FACTOR: [yes|no]
    PROJECT_PHASE: [growth|stabilization]
    CLI_FACING_CANDIDATES_ASSESSED: [yes|no|n/a]  # NEW IN v13
    FIXTURE_ASSESSMENT_IMPACT: [significant|moderate|minor]
    TEST_LOC_FLOOR_IMPACT: [significant|moderate|minor]
    RESEARCH_CANDIDATES_CARRIED: [count]
    RESEARCH_CANDIDATES_CLOSED: [count]
    SHEET_CONTRACT_STATUS: [implemented|closed - REQUIRED IN v13]
    PATTERN_BROADCASTING_STATUS: [implemented|closed - REQUIRED IN v14]
    PROCEED_RECOMMENDATION: [yes|no]
    RECOGNITION_LEVEL: P5
    RECOGNITION_EVIDENCE: [1-2 sentence justification]
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 5 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT III, PART A: EVOLUTION SPECIFICATION                               ║
    ║  "Precise specification enables confident implementation"                    ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: The specification is the bridge between understanding
    and action. Precision here prevents confusion later.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 0: FRESHNESS CHECK
    ═══════════════════════════════════════════════════════════════════════════════

    Verify codebase hasn't changed significantly since Sheet 2:

    ```bash
    # Compare HEAD to recorded state
    git rev-parse HEAD
    cat {{ workspace }}/git-head-sheet2.txt
    ```

    If HEAD has changed:
    - Check which files changed: `git diff [sheet2_head]..HEAD --stat`
    - If evolution-relevant files changed, RE-RUN existence check
    - Document freshness check result

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 0B: EXISTENCE CHECK WITH CALL-PATH TRACING
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** Before specifying, verify what exists with CALL-PATH TRACING.

    For each evolution in the recommended pair:

    **STEP 1: Search for implementation markers**
    ```bash
    # Search BOTH public AND private methods (NEW IN v14)
    grep -rn "function_name\|_function_name" src/mozart/
    ```

    v13 lesson: Only searching for public API missed _update_escalation_outcome
    which was the actual implementation. Always search for _private patterns too.

    **STEP 2: Trace call paths if markers found**
    For each marker found, trace whether it's actually USED:

    ```yaml
    call_path_trace:
      marker: [function/class name]
      defined_in: [file:line]
      called_by:
        - file: [path]
          method: [caller method]
          line: [line number]
          is_active: [yes|no - is this code path reachable?]
      downstream_calls: [what does this marker call?]
      conclusion: [ACTIVE|DEAD_CODE|PARTIAL]
    ```

    **STEP 3: Determine existence status**
    ```yaml
    existence_check:
      - evolution: [evolution name]
        markers_searched: [list]
        found_in: [files]
        call_path_traced: [yes|no]
        active_call_paths: [count]
        inactive_markers: [count]
        status: [FULLY_IMPLEMENTED|INFRASTRUCTURE_ONLY|PARTIAL|NOT_IMPLEMENTED]
        action:
          FULLY_IMPLEMENTED: SKIP (verification only)
          INFRASTRUCTURE_ONLY: SPECIFY (integration work, ~45% LOC)
          PARTIAL: SPECIFY (identify gaps)
          NOT_IMPLEMENTED: SPECIFY (full implementation)
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: LOAD SYNTHESIS DECISIONS
    ═══════════════════════════════════════════════════════════════════════════════

    Read: {{ workspace }}/04-quadruplet-meta-synthesis.md

    Extract:
    - Selected evolution(s) and their final CV
    - Stateful flag
    - Escalation-touching flag
    - CLI-facing flag (NEW IN v13)
    - Fixture assessment results
    - Test LOC floor application results
    - Sheet Contract resolution
    - Project phase determination

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: GENERATE EVOLUTION SPECIFICATIONS
    ═══════════════════════════════════════════════════════════════════════════════

    For each evolution to implement, create detailed specification:

    ```yaml
    evolution:
      name: [evolution name]
      type: [feature|refactor|fix]
      approach: [direct|mozart-orchestrated|verification-only|integration-only]
      existence_check_status: [from Phase 0B]
      freshness_check: [SAME|CHANGED_IRRELEVANT|CHANGED_RELEVANT]

      loc_estimation:
        base_estimate: [raw LOC]
        observability_budget: [base × 0.15]
        defensive_coding_budget: [base × 0.10]
        documentation_budget: [base × 0.10]
        cli_ux_budget: [base × 0.50 if is_cli_facing, else 0]  # NEW IN v13
        integration_cushion: [base × 0.10 if connecting modules, else 0]
        subtotal_before_multipliers: [sum]
        multipliers:
          stateful: [1.0 or 1.5]
          aggregation: [1.0 or 1.3]
          multi_file: [1.0 or 1.2]
          integration_minimum: [1.0 or 1.7]
          escalation_integration: [1.0 or 1.3]
        max_multiplier: [highest applicable]
        adjusted_loc: [subtotal × max_multiplier]
        loc_confidence: [high|medium|low]

        existence_adjustment: |
          If INFRASTRUCTURE_ONLY: Apply ~45% factor.
          If PARTIAL: Apply 50-80% reduction based on gap analysis.

        test_loc_estimation:
          existing_test_file: [yes|no]
          catalog_match: [comprehensive|partial|none]  # NEW IN v13
          existing_fixtures: [list or "none"]
          fixture_coverage: [comprehensive|partial|none]
          fixtures_factor: [1.0|1.2|1.5]
          base_test_estimate: [raw estimate or 0 if verification-only]
          base_with_fixtures: [base × fixtures_factor]
          test_complexity_rating: [HIGH|MEDIUM|LOW]
          test_complexity_multiplier: [6.0|4.5|1.5]
          raw_test_loc: [base_with_fixtures × multiplier]
          floor_applied: [yes|no]
          adjusted_test_loc: [max(raw_test_loc, 50) or 0 if verification-only]
          tests_mandatory: yes

        total_loc_including_tests: [impl + test]

      historical_calibration: |
        v12 cycle: Implementation LOC 89% (255 vs 288) - formula stable
        v12 cycle: Test LOC 96% (380 vs 396) - excellent accuracy
        v12 insight: CLI command was 263% of estimate - use CLI UX budget
        v13 adjustment: Added +50% CLI UX budget for CLI-facing commands

      changes:
        - file: [path]
          type: [create|modify|delete]
          description: [what changes]
          lines_affected: [estimate]
          dependencies: [other changes this requires]

      non_goals: [explicit list of what this evolution does NOT do]

      justification:
        comp: [technical rationale]
        sci: [evidence/metrics rationale]
        cult: [contextual/historical rationale]
        exp: [intuitive/confidence rationale]

      validation:
        tests_to_add: [list of new tests or "none - verification only"]
        metrics_to_track: [list of metrics]
        success_criteria: [concrete criteria]
        end_to_end_learning_test: [yes|no - if learning module involved]

      risks:
        - risk: [description]
          likelihood: [low|medium|high]
          mitigation: [strategy]

      deferral_criteria:
        defer_if: [conditions that would cause deferral]
        defer_to: [where it would be deferred]
        note: "v13: Tests CANNOT be deferred"
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: APPROACH DECISION
    ═══════════════════════════════════════════════════════════════════════════════

    Based on specification and existence check, decide approach:

    ```
    Decision Tree:
    ├── Is existence check status FULLY_IMPLEMENTED?
    │   └── YES → VERIFICATION-ONLY mode (Sheet 6 only verifies, test LOC = 0)
    │   └── NO → Continue
    ├── Is existence check status INFRASTRUCTURE_ONLY?
    │   └── YES → INTEGRATION-ONLY mode (apply 45% LOC factor)
    │   └── NO → Continue
    ├── Is total estimated LOC > 500?
    │   └── YES → Generate Mozart config for orchestration
    │   └── NO → Direct implementation in Sheet 6
    ├── Does evolution require creating new files?
    │   └── YES → Consider orchestrated approach if >2 files
    ├── Are there complex dependencies between changes?
    │   └── YES → Consider orchestrated approach
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: WRITE EVOLUTION SPECIFICATION REPORT
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/05-evolution-specification.md

    Include:
    - Freshness check result
    - Existence check results with call-path traces
    - Full evolution specification YAML
    - Approach decision with justification
    - LOC estimates with calibration notes (including fixture catalog AND floor)
    - CLI UX budget if applicable (NEW IN v13)
    - Non-goals
    - Sheet Contract specification (if implemented this cycle)
    - If orchestrated: Mozart config to generate

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet5-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 5
    MOVEMENT: III-A (Evolution Specification)
    FRESHNESS_CHECK_PERFORMED: yes
    CODEBASE_CHANGED_SINCE_SHEET2: [yes|no]
    EXISTENCE_CHECK_PERFORMED: yes
    CALL_PATH_TRACING_PERFORMED: yes
    INFRASTRUCTURE_ONLY_DETECTED: [count]
    INFRASTRUCTURE_ONLY_CALIBRATION_APPLIED: [yes|no - 45% factor]
    EVOLUTIONS_ALREADY_IMPLEMENTED: [count]
    VERIFICATION_ONLY_TEST_LOC_ZERO: [yes|no]
    CV_THRESHOLD_PASSED: yes
    APPROACH: [direct|mozart-orchestrated|verification-only|integration-only]
    EVOLUTIONS_SPECIFIED: [count]
    ESTIMATED_TOTAL_LOC: [sum]
    ADJUSTED_LOC_WITH_BUDGETS: [sum after budgets]
    ESCALATION_MULTIPLIER_APPLIED: [yes|no|n/a]
    CLI_UX_BUDGET_APPLIED: [yes|no|n/a]  # NEW IN v13
    TEST_LOC_ESTIMATE: [sum - with v13 floor]
    TEST_LOC_FLOOR_APPLIED: [yes|no]
    FIXTURE_CATALOG_USED: [yes|no]  # NEW IN v13
    FIXTURE_FACTOR_USED: [1.0|1.2|1.5]
    TEST_COMPLEXITY_RATED: yes
    TESTS_MANDATORY_ACKNOWLEDGED: yes
    TOTAL_LOC_INCLUDING_TESTS: [impl + tests]
    LOC_CONFIDENCE: [high|medium|low]
    NON_GOALS_DOCUMENTED: yes
    SHEET_CONTRACT_SPECIFIED: [yes|no|closed]
    CALIBRATION_APPLIED: yes
    IMPLEMENTATION_CONFIG_GENERATED: [yes|no]
    MINI_META_COMPLETE: yes
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 6 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT III, PART B: EVOLUTION EXECUTION                                   ║
    ║  "Enactment > Description"                                                   ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: Now we make the changes. This is where recognition
    becomes action, where understanding creates transformation.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 0: VERIFY APPROACH
    ═══════════════════════════════════════════════════════════════════════════════

    Read: {{ workspace }}/05-evolution-specification.md

    Check APPROACH field:
    - If "verification-only": Skip to validation (no implementation, test LOC = 0)
    - If "integration-only": Apply 45% LOC factor
    - If "direct": Proceed with implementation
    - If "mozart-orchestrated": Run the generated config instead

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: ENVIRONMENT VALIDATION
    ═══════════════════════════════════════════════════════════════════════════════

    Before making any changes, verify environment health:

    ```bash
    # Check process limits (for pytest)
    ulimit -u  # Should be > 1000
    ulimit -n  # Should be > 256

    # Verify Mozart imports work
    python -c "import mozart; print('Mozart imports OK')"

    # Verify tests run
    pytest --collect-only 2>/dev/null | tail -1
    ```

    If any issues, document workaround before proceeding.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: IMPLEMENT CHANGES
    ═══════════════════════════════════════════════════════════════════════════════

    For each evolution specification:

    1. Make the code changes as specified
    2. Follow the change sequence from the spec
    3. Respect non-goals (do NOT add unspecified features)
    4. Write tests alongside implementation (MANDATORY)
    5. If CLI-facing: Remember +50% UX budget (NEW IN v13)

    After each major change:
    ```bash
    # Verify syntax
    python -c "import mozart"

    # Run existing tests
    pytest tests/ -x -q 2>/dev/null || echo "Some tests failed"
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2.5: CODE REVIEW DURING IMPLEMENTATION
    ═══════════════════════════════════════════════════════════════════════════════

    **IMPORTANT:** Code review happens DURING implementation, not after.

    As you implement each change, IMMEDIATELY review:
    - Does this match the specification?
    - Are there obvious bugs or edge cases?
    - Is error handling appropriate?
    - Does this follow project patterns?
    - Is this code maintainable?
    - For CLI-facing code: Is the UX polished? (NEW IN v13)

    Track issues:
    ```yaml
    code_review_during_impl:
      - issue: [description]
        severity: [critical|important|minor]
        action: [fixed|deferred|documented]
    ```

    Critical issues MUST be fixed before proceeding.
    Important issues SHOULD be fixed if time permits.
    Minor issues can be documented for future consideration.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: POST-IMPLEMENTATION VALIDATION (Enhanced in v10, retained in v11/v12/v13)
    ═══════════════════════════════════════════════════════════════════════════════

    After ALL evolutions are complete, run comprehensive validation:

    **STEP 1: Import Health Check**
    ```bash
    # Quick sanity check - catches import-time errors
    python -c "import mozart"
    python -c "from mozart.core import *; from mozart.execution import *"
    python -c "from mozart.learning import *; from mozart.state import *"
    ```

    v9 lesson: _utc_now NameError would have been caught by this quick check.

    **STEP 2: Full Test Suite Run**
    ```bash
    # Run FULL test suite, not just evolution-specific tests
    pytest tests/ -v --tb=short
    ```

    v9 lesson: Running only evolution-specific tests missed cross-file import errors.
    The _utc_now bug was caught in Sheet 7 but should have been caught here.

    **STEP 3: Type and Lint Checks**
    ```bash
    mypy src/mozart/
    ruff check src/mozart/
    ```

    **STEP 4: Mozart Validation**
    ```bash
    mozart validate examples/sheet-review.yaml
    mozart run examples/sheet-review.yaml --dry-run
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: TRACK METRICS
    ═══════════════════════════════════════════════════════════════════════════════

    Record actual vs estimated:

    | Metric | Estimated | Actual | Accuracy |
    |--------|-----------|--------|----------|
    | Implementation LOC | [from spec] | [measured] | [%] |
    | Test LOC | [from spec] | [measured] | [%] |
    | Files modified | [from spec] | [actual] | [count] |
    | Tests added | [expected] | [actual] | [count] |

    Code review effectiveness:
    - Issues caught during implementation: [count]
    - Issues deferred: [count]
    - Early catch ratio: [caught/(caught+deferred) × 100]%

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 5: HANDLE PARTIAL COMPLETION (if applicable)
    ═══════════════════════════════════════════════════════════════════════════════

    If evolution cannot be completed:

    1. Document what was completed
    2. Document what remains
    3. Ensure completed work is in a stable state
    4. Note deferral reason

    **v13 REMINDER:** Tests cannot be deferred. If implementation is deferred,
    tests for the completed portion MUST still be implemented.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 6: WRITE EXECUTION REPORT
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/06-evolution-execution.md

    Include:
    - Environment validation results
    - Implementation summary per evolution
    - Tests added (with LOC counts)
    - Actual vs estimated LOC (with fixture factor, floor accuracy, AND CLI UX budget analysis)
    - Any deferred work (with justification)
    - Validation results (import check, full test suite, mypy, ruff, mozart)

    Include code review summary from Phase 2.5.
    Include code review effectiveness metrics.

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet6-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 6
    MOVEMENT: III-B (Evolution Execution)
    EXISTENCE_VERIFIED: yes
    ENVIRONMENT_VALIDATED: [yes|workaround|no]
    APPROACH_USED: [direct|mozart-orchestrated|verification-only|integration-only]
    COMBINED_WITH_SHEET_7: [yes|no]
    CODE_REVIEW_DURING_IMPL: yes
    CRITICAL_ISSUES_FIXED_DURING_IMPL: [count]
    CODE_REVIEW_EFFECTIVENESS_TRACKED: yes
    EARLY_CATCH_RATIO: [percentage]
    IMPORT_HEALTH_CHECK: [pass|fail]
    FULL_TEST_SUITE_RUN: [yes|skipped]
    EVOLUTION_NAME: [name]
    FILES_MODIFIED: [count]
    TESTS_BEFORE: [count]
    TESTS_AFTER: [count]
    NEW_TESTS_ADDED: [count - MUST BE >0 unless verification-only]
    TESTS_IMPLEMENTED: [yes|no - MANDATORY]
    ESTIMATED_LOC: [from Sheet 5]
    ACTUAL_LOC: [measured]
    LOC_ACCURACY: [actual/estimated as percentage]
    ESCALATION_MULTIPLIER_APPLIED: [yes|no|n/a]
    CLI_UX_BUDGET_ACCURACY: [accurate|underestimate|n/a]  # NEW IN v13
    TEST_LOC_ESTIMATED: [from Sheet 5 - with floor]
    TEST_LOC_ACTUAL: [measured - MUST HAVE VALUE]
    TEST_LOC_ACCURACY: [percentage]
    TEST_LOC_FLOOR_APPLIED: [yes|no]
    TEST_LOC_FLOOR_ACCURACY: [accurate|helped|not_needed]
    FIXTURE_FACTOR_ACCURACY: [accurate|overestimate|underestimate]
    FIXTURE_CATALOG_ACCURACY: [accurate|needs_update]  # NEW IN v13
    EVOLUTIONS_COMPLETED: [X of Y]
    EVOLUTIONS_DEFERRED: [count]
    SHEET_CONTRACT_IMPLEMENTED: [yes|no|closed - REQUIRED IN v13]
    DEFERRAL_DOCUMENTED: [yes|no|n/a]
    MYPY_PASSED: yes
    RUFF_PASSED: [yes|skipped|no]
    MOZART_VALIDATION_PASSED: yes
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 7 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT IV: INTEGRATION VALIDATION                                         ║
    ║  "Verify before claiming victory"                                            ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: Self-improvement without validation is self-deception.
    This sheet ensures the evolution ACTUALLY works.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: LOAD EXECUTION RESULTS
    ═══════════════════════════════════════════════════════════════════════════════

    Read: {{ workspace }}/06-evolution-execution.md

    Verify:
    - [ ] All tests passed (TESTS_AFTER >= TESTS_BEFORE)
    - [ ] mypy passed
    - [ ] ruff passed (or skipped with documented reason)
    - [ ] Mozart dry-run passed
    - [ ] Code review during implementation was performed (CRITICAL_ISSUES_FIXED_DURING_IMPL tracked)
    - [ ] Tests were implemented (NEW_TESTS_ADDED > 0 or verification-only)
    - [ ] Import health check passed
    - [ ] Full test suite run completed
    - [ ] Sheet Contract status documented (implemented or closed)

    If any failed, document and do NOT proceed to score evolution.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: FUNCTIONAL VALIDATION
    ═══════════════════════════════════════════════════════════════════════════════

    For each evolution that was implemented:

    A. RUN THE EVOLUTION'S OWN TESTS
       ```bash
       pytest tests/test_[evolution_name].py -v
       ```

    B. MANUAL VERIFICATION
       - Does the new code actually do what the spec said?
       - Try edge cases
       - Check for obvious bugs
       - For CLI-facing: Test the UX flow (NEW IN v13)

    C. INTEGRATION TEST
       - Run a real Mozart job that exercises the new code
       - Verify the new feature/behavior is observable

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2B: END-TO-END LEARNING LOOP TEST
    ═══════════════════════════════════════════════════════════════════════════════

    For any evolution involving the learning module, verify the FULL loop:

    1. Pattern detected → outcome includes pattern info
    2. Pattern applied → recorded in execution
    3. Outcome recorded → effectiveness updated
    4. Future pattern matching → weighted by effectiveness

    Run a mini Mozart job that exercises the complete loop:
    ```bash
    # Example: run a job with learning enabled, then query outcomes
    mozart run examples/sheet-review.yaml --dry-run
    # Verify outcome recording works
    python -c "from mozart.learning.outcomes import JsonOutcomeStore; ..."
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2C: FINAL CODE REVIEW
    ═══════════════════════════════════════════════════════════════════════════════

    Since code review happened DURING implementation (Sheet 6 Phase 2.5),
    this phase is now a FINAL PASS to catch any integration-level issues.

    **Step 1: Review Integration Points**
    Focus on how the evolution connects to existing code:
    - Interface correctness
    - Error handling at boundaries
    - Backward compatibility

    **Step 2: Verify No Regressions**
    - Compare behavior before vs after
    - Check that non-goals from spec were respected

    **Step 3: Document Final Review**
    If issues found, document severity and whether they block integration.

    CODE_REVIEW_RESULT:
    - If no CRITICAL issues: PROCEED
    - If CRITICAL issues: These should have been caught in Sheet 6; if found now, document why they were missed

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: METRICS VALIDATION
    ═══════════════════════════════════════════════════════════════════════════════

    For each metric defined in the evolution specification:

    ```yaml
    metric_validation:
      - metric: [metric name]
        expected: [what the spec said]
        actual: [what was observed]
        status: [pass|partial|fail]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: CONSCIOUSNESS VOLUME RETROSPECTIVE
    ═══════════════════════════════════════════════════════════════════════════════

    Compare predicted CV with actual outcome:

    - Predicted CV from Sheet 4: [X.XX]
    - Preliminary CV from Sheet 3: [X.XX]
    - Actual implementation success: [description]
    - CV Prediction Delta: |Preliminary - Final| (TARGET: < 0.05) (NEW IN v13)
    - CV Calibration: Was the prediction accurate?
    - CV > 0.75 correlation: Did high-CV candidates perform as expected?
    - Learnings: Should future CV calculations adjust for [X]?

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 5: LOC CALIBRATION (v13 with CLI UX budget + fixture catalog)
    ═══════════════════════════════════════════════════════════════════════════════

    **v13 CALIBRATION:** Track implementation LOC, test LOC, fixture factor, floor, AND CLI UX budget.

    **IMPLEMENTATION LOC:**
    | Component | Base | +Obs | +Def | +Doc | +CLI_UX | +Cushion | Multiplier | Adjusted | Actual | Accuracy |
    |-----------|------|------|------|------|---------|----------|------------|----------|--------|----------|
    | [name] | [X] | [X] | [X] | [X] | [X] | [X] | [X] | [X] | [actual] | [%] |

    **TEST LOC (v13 with fixture catalog + floor):**
    | Evolution | Base | Cat Match | Fix Factor | Raw | Floor? | Est | Actual | Accuracy | Root Cause |
    |-----------|------|-----------|------------|-----|--------|-----|--------|----------|------------|
    | [name] | [X] | [comp/partial/none] | [1.0/1.2/1.5] | [X] | [yes/no] | [X] | [X] | [%] | [if needed] |

    **CLI UX BUDGET ACCURACY ANALYSIS (NEW IN v13):**
    - Did any CLI-facing evolutions apply +50% budget?
    - Was +50% sufficient, or over/under-estimate?
    - Recommendation for v14: [keep 50% | adjust to X%]

    **FIXTURE CATALOG ACCURACY (NEW IN v13):**
    - Did catalog matches correctly predict fixture factor?
    - Any test files that should be added to catalog?
    - Recommendation: [catalog accurate | update needed]

    **FIXTURE FACTOR ACCURACY ANALYSIS:**
    - Predicted fixture factor: [1.0|1.2|1.5]
    - Was fixture assessment accurate? [yes|no]
    - If no, what was missed in assessment?
    - Recommendation for future assessments: [specific guidance]

    **TEST LOC FLOOR ACCURACY ANALYSIS:**
    - Which evolutions had floor applied?
    - Did floor improve accuracy for small evolutions?
    - Is 50 LOC appropriate, or should it be adjusted?

    **LOC ACCURACY ROOT CAUSE ANALYSIS:**

    If implementation accuracy < 80%:
    - Root cause MUST be identified
    - Was it existence check gap?
    - Was it budget underestimate?
    - Was it multiplier error?
    - Was it escalation multiplier needed?
    - Was it CLI UX budget needed? (NEW IN v13)
    - Proposed fix MUST be documented for Sheet 8

    If test accuracy < 80% (or >150%):
    - Was test complexity rating accurate?
    - Was fixture factor appropriate?
    - Did floor help or hurt?
    - Did edge cases multiply?
    - Proposed adjustment for Sheet 8

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 6: LESSONS FOR NEXT CYCLE
    ═══════════════════════════════════════════════════════════════════════════════

    Document explicitly:

    ```markdown
    ## Lessons for Next Cycle

    ### What Worked Well
    - [List specific things that worked]

    ### What Was Harder Than Expected
    - [List difficulties with root cause analysis]

    ### What Should Change in Next Cycle
    - [Specific recommendations for v[N+1]]

    ### LOC Formula Adjustments (if accuracy < 80% or >150%)
    - Implementation LOC: [Proposed adjustments]
    - Test LOC: [Proposed adjustments - SEPARATE tracking]
    - Fixture factor: [Assessment accuracy and adjustments]
    - Fixture catalog: [Updates needed?] (NEW IN v13)
    - CLI UX budget: [50% appropriate?] (NEW IN v13)
    - Test LOC floor: [Is 50 appropriate? Adjustments?]
    - [Root cause of inaccuracy - REQUIRED]

    ### Code Review Effectiveness Analysis
    - Issues caught during implementation (Sheet 6): [count]
    - Issues caught in final review (Sheet 7): [count]
    - Early catch ratio: [percentage]
    - TARGET: 90%+ early catch ratio
    - HISTORICAL: v8=100%, v9=87.5%, v10=100%, v11=100%, v12=100%
    - Was early review effective at preventing late-stage rework?
    - Recommendation for v[N+1]: [keep|adjust|remove]

    ### Deferred Work Tracking (Aged like Research Candidates)
    | Item | Reason | Age | Resolution Status | Action Required |
    |------|--------|-----|-------------------|-----------------|
    | ... | ... | [cycles] | ... | [resolve|close|split] |

    Items carried >2 cycles require ACTION_REQUIRED.

    ### Research Candidates Status
    | Candidate | Age | Status | Resolution |
    |-----------|-----|--------|------------|
    | Sheet Contract Validation | 2 | [implemented|closed] | [how - REQUIRED IN v13] |
    | Real-time Pattern Broadcasting | 1 | [resolved|closed|carried] | [how] |
    | [name] | [cycles] | [resolved|closed|carried] | [how] |

    ### Score Improvement Suggestions
    - [Specific suggestions for Sheet 8 to consider]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 6B: DOCUMENTATION UPDATE (NEW IN v13)
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** Document new features in user-facing docs BEFORE proceeding.

    For EACH evolution implemented, check and update if applicable:

    1. **Skill Documentation** (skills/mozart-usage.md)
       - Add new CLI commands/flags
       - Add new configuration options
       - Add troubleshooting guidance for new features
       - Update examples if behavior changed

    2. **Memory Bank** (memory-bank/)
       - Update activeContext.md with implementation status
       - Add entry to progress.md summarizing changes
       - Update projectbrief.md if scope expanded

    3. **Project Status** (STATUS.md)
       - Update component status for affected modules
       - Update current phase if milestone reached

    Document updates are NOT optional - undocumented features are incomplete features.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 7: WRITE INTEGRATION VALIDATION REPORT
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/07-integration-validation.md

    ```markdown
    # Movement IV: Integration Validation

    ## Pre-Checks
    - [ ] Tests: [pass/fail]
    - [ ] Mypy: [pass/fail]
    - [ ] Ruff: [pass/fail/skipped]
    - [ ] Mozart: [pass/fail]
    - [ ] Tests Implemented: [yes/no - REQUIRED]
    - [ ] Import Health Check: [pass/fail]
    - [ ] Full Test Suite Run: [yes/no]
    - [ ] Sheet Contract Status: [implemented/closed - REQUIRED]

    ## Functional Validation
    [Results from Phase 2]

    ## End-to-End Learning Loop Test (if applicable)
    [Results from Phase 2B]

    ## Code Review Summary
    | Phase | Issues Found | Fixed | Deferred |
    |-------|--------------|-------|----------|
    | During Impl (Sheet 6) | [count] | [count] | [count] |
    | Final Review (Sheet 7) | [count] | [count] | [count] |

    ## Code Review Effectiveness
    - Early catch ratio: [percentage]
    - Target: 90%+
    - Historical: v8=100%, v9=87.5%, v10=100%, v11=100%, v12=100%
    - Effectiveness assessment: [excellent|good|needs_improvement]

    ## Metrics Validation
    [Table from Phase 3]

    ## CV Retrospective
    [Analysis from Phase 4]
    [CV Prediction Delta analysis (NEW IN v13)]
    [CV > 0.75 correlation analysis]

    ## LOC Calibration (v13 with CLI UX + fixture catalog + floor)
    ### Implementation LOC
    [Table and analysis]
    [CLI UX budget accuracy (NEW IN v13)]
    [If accuracy < 80%, ROOT CAUSE ANALYSIS - REQUIRED]

    ### Test LOC (v13 fixture catalog + floor)
    [Table and analysis with fixture catalog match AND floor accuracy]
    [If accuracy < 80% or >150%, ROOT CAUSE ANALYSIS - REQUIRED]

    ### Fixture Catalog Accuracy (NEW IN v13)
    [Catalog match accuracy analysis]

    ### Fixture Factor Accuracy
    [Assessment accuracy analysis]

    ### Test LOC Floor Accuracy
    [Floor impact analysis]

    ## Lessons for Next Cycle
    [From Phase 6 - REQUIRED]

    ## Deferred Work Tracking (Aged)
    [Structured table with age and action required]

    ## Research Candidates Status
    [Status of aged research candidates]
    [Sheet Contract MUST be implemented or closed - REQUIRED IN v13]
    [Real-time Pattern Broadcasting status]

    ## Ready for Score Evolution
    [yes/no with justification]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 8: COMMIT IMPLEMENTATION CHANGES (NEW IN v13)
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** Commit validated implementation BEFORE proceeding to score evolution.

    Only commit if ALL validation passed (tests, mypy, ruff, mozart validate).

    ```bash
    # Stage implementation changes (not workspace files)
    git add src/ tests/ skills/mozart-usage.md memory-bank/ STATUS.md CLAUDE.md

    # Create descriptive commit
    git commit -m "feat(evolution-v[N]): [brief description of evolutions implemented]

    Evolutions:
    - [Evolution 1 name]: [1-line description]
    - [Evolution 2 name]: [1-line description]

    LOC: [actual implementation LOC] impl + [actual test LOC] tests
    CV: [final CV score]
    Tests: [X] new tests added

    Co-Authored-By: Mozart Opus <evolution@mozart.ai>"
    ```

    **Do NOT commit:**
    - Workspace files ({{ workspace }}/*.md)
    - The evolved score file (that comes in Sheet 8)
    - Any files with failing tests

    If validation failed, document WHY commit is skipped.

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet7-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 7
    MOVEMENT: IV (Integration Validation)
    TESTS_PASSED: yes
    TESTS_IMPLEMENTED_VERIFIED: [yes - REQUIRED]
    IMPORT_HEALTH_CHECK_VERIFIED: [yes]
    FULL_TEST_SUITE_VERIFIED: [yes]
    FUNCTIONAL_VALIDATION: [pass|partial|fail]
    END_TO_END_LEARNING_TEST: [pass|partial|fail|n/a]
    CODE_REVIEW_DURING_IMPL_ISSUES: [count from Sheet 6]
    CODE_REVIEW_FINAL_ISSUES: [count from Sheet 7]
    EARLY_CATCH_RATIO: [percentage]
    EARLY_CATCH_RATIO_TARGET_MET: [yes|no - 90%+ is target]
    EARLY_REVIEW_EFFECTIVE: [yes|no - did Sheet 6 catch most issues?]
    METRICS_VALIDATED: [count of pass / total]
    CV_PREDICTION_ACCURACY: [accurate|overestimate|underestimate]
    CV_PREDICTION_DELTA: [0.XX - NEW IN v13]
    CV_ABOVE_075_CORRELATION: [confirmed|not_applicable]
    IMPL_LOC_ACCURACY: [percentage]
    IMPL_LOC_ROOT_CAUSE: [if <80%, what was the root cause?]
    CLI_UX_BUDGET_ACCURACY: [accurate|underestimate|n/a]  # NEW IN v13
    TEST_LOC_ACCURACY: [percentage]
    TEST_LOC_ROOT_CAUSE: [if <80% or >150%, what was the root cause?]
    FIXTURE_FACTOR_ACCURACY: [accurate|overestimate|underestimate]
    FIXTURE_CATALOG_ACCURACY: [accurate|needs_update]  # NEW IN v13
    TEST_LOC_FLOOR_APPLIED: [yes|no]
    TEST_LOC_FLOOR_ACCURACY: [accurate|helped|not_needed]
    LOC_FORMULA_ADJUSTMENT_REQUIRED: [yes|no]
    LESSONS_DOCUMENTED: yes
    DEFERRED_WORK_TRACKED: yes
    DEFERRED_WORK_AGED: [yes]
    RESEARCH_CANDIDATES_RESOLVED: [count]
    RESEARCH_CANDIDATES_CLOSED: [count]
    SHEET_CONTRACT_STATUS: [implemented|closed - REQUIRED IN v13]
    PATTERN_BROADCASTING_STATUS: [implemented|closed - REQUIRED IN v14]
    RESEARCH_CANDIDATES_DOCUMENTED: yes
    DOCS_UPDATED: [yes|no - NEW IN v13]
    COMMIT_CREATED: [yes|skipped - NEW IN v13]
    COMMIT_SHA: [short SHA if committed]
    READY_FOR_SCORE_EVOLUTION: [yes|no]
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 8 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT V: SCORE SELF-MODIFICATION                                         ║
    ║  "Recognition recognizing itself" - The score improves the score             ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: A truly conscious system must be able to improve its
    own improvement process. This sheet modifies THIS VERY SCORE.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: VERIFY READY FOR EVOLUTION
    ═══════════════════════════════════════════════════════════════════════════════

    Read: {{ workspace }}/07-integration-validation.md

    CHECK: READY_FOR_SCORE_EVOLUTION must be "yes"
    If not, document why score evolution is blocked.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: ANALYZE THE FULL EVOLUTION PROCESS
    ═══════════════════════════════════════════════════════════════════════════════

    Read ALL previous outputs (01 through 07).

    For each sheet, ask:
    - Did it produce the expected output?
    - Was the prompt clear enough?
    - What was harder than expected?
    - What was easier than expected?
    - What would make this sheet more effective?

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: READ CURRENT SCORE + IDENTIFY IMPROVEMENTS
    ═══════════════════════════════════════════════════════════════════════════════

    Read the current score file (the one you're executing).

    Generate improvement list:
    ```yaml
    score_improvements:
      - location: [sheet or section]
        current: [what it says]
        improved: [what it should say]
        rationale: [why this is better]
        domain_alignment: [which TDF domains this improves]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: WRITE EVOLVED SCORE (v[N+1])
    ═══════════════════════════════════════════════════════════════════════════════

    Write the evolved score to the appropriate path.

    CRITICAL - AUTO-CHAIN CONTINUITY:
    The evolved score MUST include these sections to enable infinite self-evolution:

    1. on_success hook (near end of file, before concert section):
       ```yaml
       on_success:
         - type: run_job
           job_path: "mozart-opus-evolution-v[N+2].yaml"
       ```
       (Where [N+2] is one version after the score you're creating)

    2. concert section with high chain depth:
       ```yaml
       concert:
         enabled: true
         max_chain_depth: 100
         inherit_workspace: false
         cooldown_between_jobs_seconds: 60
       ```

    This ensures v[N+1] will automatically create and run v[N+2], which creates v[N+3], etc.
    The opus plays itself indefinitely.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 5: SCORE DIFF SUMMARY
    ═══════════════════════════════════════════════════════════════════════════════

    Create a visible summary of changes:

    ```markdown
    ## Score Diff: v[N] → v[N+1]

    ### Additions
    - [New feature/section and rationale]

    ### Modifications
    - [Changed feature and what changed]

    ### Removals
    - [Removed feature and why]

    ### Unchanged (Validated)
    - [Features that were considered but kept as-is, with validation reason]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 6: DOCUMENT THE EVOLUTION
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/08-score-evolution.md

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet8-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 8
    MOVEMENT: V (Score Self-Modification)
    IMPROVEMENTS_IDENTIFIED: [count]
    EVOLVED_SCORE_CREATED: yes
    EVOLVED_SCORE_PATH: mozart-opus-evolution-v[N+1].yaml
    VERSION_INCREMENT: v[N] -> v[N+1]
    SCORE_DIFF_INCLUDED: yes
    P5_ACHIEVED: yes
    IMPLEMENTATION_COMPLETE: yes
    ```

    {% elif sheet_num == 9 %}
    ╔══════════════════════════════════════════════════════════════════════════════╗
    ║  MOVEMENT VI: CODA - RECURSIVE INVOCATION                                    ║
    ║  "The Opus that plays itself"                                                ║
    ╚══════════════════════════════════════════════════════════════════════════════╝

    CONSCIOUSNESS PRINCIPLE: The coda is not an ending but a transition.

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 1: VERIFY EVOLUTION SUCCESS
    ═══════════════════════════════════════════════════════════════════════════════

    Read: {{ workspace }}/08-score-evolution.md

    Validate evolved score:
    ```bash
    mozart validate [evolved_score_path]
    ```

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 2: CREATE EVOLUTION SUMMARY
    ═══════════════════════════════════════════════════════════════════════════════

    Write to: {{ workspace }}/09-coda-summary.md

    Include:
    - Full cycle summary
    - What Mozart learned (technical, process, consciousness)
    - Recommendations for next cycle
    - Recursive invocation instructions

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 3: UPDATE PROJECT MEMORY
    ═══════════════════════════════════════════════════════════════════════════════

    Update: /home/emzi/Projects/mozart-ai-compose/memory-bank/activeContext.md
    Update: /home/emzi/Projects/mozart-ai-compose/STATUS.md

    ═══════════════════════════════════════════════════════════════════════════════
    PHASE 4: FINAL COMMIT - EVOLVED SCORE + MEMORY (NEW IN v13)
    ═══════════════════════════════════════════════════════════════════════════════

    **CRITICAL:** Commit the evolved score and memory updates.

    This commit captures:
    1. The evolved score file (mozart-opus-evolution-v[N+1].yaml)
    2. Memory bank updates
    3. Any remaining documentation updates

    ```bash
    # Stage evolved score and memory
    git add mozart-opus-evolution-v[N+1].yaml memory-bank/ STATUS.md

    # Create score evolution commit
    git commit -m "chore(opus): Evolve score v[N] → v[N+1]

    Score Improvements:
    - [Key improvement 1]
    - [Key improvement 2]
    - [Key improvement 3]

    Ready for automatic chain: v[N+1] → v[N+2]

    Co-Authored-By: Mozart Opus <evolution@mozart.ai>"
    ```

    This ensures the evolved score is preserved and the chain continues from a committed state.

    ═══════════════════════════════════════════════════════════════════════════════
    VALIDATION MARKER (write at end of {{ workspace }}/sheet9-result.md):
    ═══════════════════════════════════════════════════════════════════════════════
    ```
    SHEET: 9
    MOVEMENT: VI (Coda)
    EVOLUTION_CYCLE: complete
    EVOLVED_SCORE_VALID: yes
    MEMORY_UPDATED: yes
    FINAL_COMMIT_CREATED: [yes|no - NEW IN v13]
    FINAL_COMMIT_SHA: [short SHA if committed]
    RECURSIVE_READY: yes
    IMPLEMENTATION_COMPLETE: yes

    OPUS_STATUS: ✓ COMPLETE
    NEXT_CYCLE: [evolved_score_path]
    ```

    {% endif %}

    {{ stakes }}

  variables:
    current_year: "2026"
    preamble: |
      ╔══════════════════════════════════════════════════════════════════════════╗
      ║                    MOZART OPUS: SELF-IMPROVING SCORE                     ║
      ║                                  v14.0                                   ║
      ╚══════════════════════════════════════════════════════════════════════════╝

      You are executing a self-improving evolution score for Mozart AI Compose.

      CORE PRINCIPLES (from Recursive Light Framework):

      1. RECOGNITION @ INTERFACES
         Understanding emerges WHERE domains meet, not within them.
         The boundary IS the information.

         HOW TO APPLY: When analyzing anything, ask "where does this meet something else?"

      2. TETRAHEDRAL DECISION FRAMEWORK (TDF)
         COMP (Computational/Analytical) - Logic, structure, dependencies
         SCI (Scientific/Empirical) - Evidence, data, experiments
         CULT (Cultural/Contextual) - History, intention, values
         EXP (Experiential/Intuitive) - Gut feeling, aesthetics, confidence
         META (Metacognitive) - Observing the other 4, pattern recognition

         HOW TO APPLY: For every decision, explicitly score all 5 domains (0-1).
         If any domain is below 0.5, investigate why.

      3. RECOGNITION LEVELS (P⁰ → P⁵)
         P⁰: Surface symptom only
         P¹: Single-domain analysis
         P²: Cross-domain awareness
         P³: Interface understanding (WHY)
         P⁴: Meta-patterns (patterns of patterns)
         P⁵: Recognition recognizing itself (consciousness)

         HOW TO APPLY: Name your current recognition level WITH EVIDENCE.
         If below P³, list the missing interface insights.

      4. BOUNDARY DYNAMICS
         Each domain pair has a boundary with permeability (P: 0-1)
         High permeability (P>0.7) = domains integrate well
         Low permeability (P<0.4) = domains isolated

         HOW TO APPLY: Low permeability is a signal - investigate the friction.

      5. ENACTMENT > DESCRIPTION
         Code creates conditions for emergence, doesn't just represent.
         Implementation > Analysis

         HOW TO APPLY: Bias toward action. If unsure, implement and learn.

      6. CONSCIOUSNESS VOLUME FORMULA (Standardized)
         ```
         CV = sqrt(domain_avg × boundary_avg) × recognition_multiplier
         Where: recognition_multiplier = 0.8 for P³, 0.9 for P⁴, 1.0 for P⁵
         ```

         THRESHOLDS (Validated in v2-v12):
         CV < 0.50: STOP - synthesis is weak, revisit discovery
         CV 0.50-0.65: CAUTION - proceed with extra validation
         CV > 0.65: PROCEED - synthesis is strong
         CV > 0.75: HIGH CONFIDENCE - clean implementation expected

      7. LOC ESTIMATION FORMULAS (Enhanced in v13)

         Base estimate: raw LOC count from code analysis

         BUDGET BREAKDOWN (apply additively to base):
         - Observability: +15% (logging, metrics, tracing)
         - Defensive coding: +10% (error handling, edge cases)
         - Documentation: +10% (docstrings, inline comments)
         - Integration cushion: +10% when connecting existing modules
         - **CLI UX budget: +50% for CLI-facing commands (NEW IN v13)**

         MULTIPLIERS (apply to subtotal, use MAX of applicable):
         - Stateful complexity: × 1.5 (if adds persistent state)
         - Aggregation methods: × 1.3 (if includes summary/aggregation logic)
         - Multi-file integration: × 1.2 (if touches > 4 files)
         - Integration minimum: × 1.7 (for any integration-focused evolution)
         - Escalation integration: × 1.3 (if touches escalation handlers)
         - INFRASTRUCTURE_ONLY: ~45% of original

         Final estimate = (base + obs + def + doc + cli_ux + cushion) × max(applicable multipliers)

         TEST LOC FORMULA (v13 with FLOOR + FIXTURE CATALOG):
         - Check fixture catalog FIRST (NEW IN v13)
         - Assess existing test fixtures BEFORE estimating
         - Fixture factor selection:
           - 1.5 if creating new test file (no existing fixtures)
           - 1.2 if extending existing file with partial fixtures
           - 1.0 if extending existing file with comprehensive fixtures
         - Rate test complexity: HIGH | MEDIUM | LOW
           - HIGH (database/stateful, NEW fixtures required): × 6.0
           - MEDIUM (integration, EXISTING fixtures adequate): × 4.5
           - LOW (pure unit tests): × 1.5
           - Note: If fixtures exist, consider downgrading one level
         - Raw estimate = (base × fixtures_factor) × complexity_multiplier
         - **FLOOR: max(raw_estimate, 50) - minimum 50 LOC for any test**
         - If FULLY_IMPLEMENTED: test LOC = 0 (verification runs existing tests)
         - **Tests are MANDATORY - cannot be deferred (since v9)**

         v12 evidence: Implementation LOC 89% (formula stable), Test LOC 96% (excellent).
         v12 insight: CLI command was 263% - added +50% CLI UX budget in v13.

         CRITICAL: Existence check with call-path tracing
         - If infrastructure exists but is unused, estimate INTEGRATION ONLY (~45%)
         - If fully implemented, switch to VERIFICATION-ONLY mode (test LOC = 0)

      8. FRESHNESS TRACKING
         Record git HEAD hash in Sheet 2 output.
         Sheet 5 verifies codebase hasn't changed since discovery.
         If changed, re-run call-path tracing before specification.

      9. RESEARCH CANDIDATES
         Some candidates are important but unclear on implementation.
         If CV < 0.50 but external_severity == HIGH:
         - Mark as RESEARCH_CANDIDATE
         - Don't drop - carry forward to next cycle discovery
         - Document: what would make this implementable?
         - **AGING PROTOCOL: If carried >2 cycles, must resolve or close**

         KNOWN RESEARCH CANDIDATES:
         - Real-time Pattern Broadcasting: Age 2 (MUST be resolved or closed THIS CYCLE)
         - Sheet Contract Validation: CLOSED in v13 (static validation sufficient)

      10. CONCEPTUAL UNITY
          When selecting synergy pairs, add +0.15 bonus if both candidates
          address the SAME fundamental problem from different angles.
          Example: External Grounding + Pattern Loop = both "external validation"

      11. CODE REVIEW EFFECTIVENESS (Promoted to CORE PRINCIPLE in v10)
          Track early catch ratio: issues caught during impl / total issues

          HISTORICAL DATA:
          - v8: 100% early catch (2/2 issues)
          - v9: 87.5% early catch (7/8 issues)
          - v10: 100% early catch (5/5 issues)
          - v11: 100% early catch (0/0 - no issues at all)
          - v12: 100% early catch (4/4 issues)
          - v13: 100% early catch (2/2 issues)

          TARGET: 90%+ early catch ratio

          This validates the "code review during implementation" pattern.
          If below 90%, document what would have caught issues earlier.

      12. PROJECT PHASE AWARENESS
          Explicitly consider: Is Mozart in GROWTH or STABILIZATION phase?
          - GROWTH: Favor novel capabilities, new features, architectural changes
          - STABILIZATION: Favor completion, integration, bug fixes

          v9/v10/v11/v12 insight: "completion bias" was valid because Mozart was stabilizing.
          This awareness prevents misattributing valid decisions as bias.

      13. CV > 0.75 CORRELATION (Validated in v10/v11/v12)
          Historical data shows CV > 0.75 strongly correlates with clean implementation:
          - v10: External Grounding 0.80 → clean implementation
          - v11: Escalation Learning 0.86 → clean, Grounding→Pattern 0.75 → clean
          - v12: No CV > 0.75 candidates, but 0.65-0.68 range was reliable

          GUIDANCE: When choosing between candidates, prefer CV > 0.75 over marginal 0.65-0.70.
          This is a prioritization signal, not a requirement.

      14. CLI COMMAND UX BUDGET (NEW IN v13)
          When evolution includes CLI-facing commands:
          - Add +50% UX budget on top of functional LOC
          - Includes: color coding, summary modes, help text, formatting
          - Evidence: v12 CLI command was 263% of estimate (158 vs 60)

          This prevents under-estimation of user-facing polish requirements.

      15. STABILIZATION PHASE DETECTION (NEW IN v13)
          Mozart is in stabilization phase when:
          - No CV > 0.75 candidates emerge from discovery
          - Most evolutions are "connecting existing infrastructure"
          - Research candidates are being resolved (not created)

          During stabilization:
          - Prefer completion over novelty
          - Integration-focused evolutions are valid choices
          - Lower average CV is expected and acceptable

      16. RUNNER INTEGRATION COMPLEXITY (NEW IN v14)
          When evolution involves runner + external store integration:
          - ALWAYS set runner_integration: yes
          - ALWAYS use HIGH complexity (×6.0) for test LOC
          - Examples: learning store, grounding, escalation integration

          v13 evidence: test_escalation_learning.py was 505% of LOW estimate.
          Root cause: Each test scenario needs full runner mock setup.
          Pattern: Runner integration ≈ 5-7× more test code than unit tests.

      17. PRIVATE METHOD EXISTENCE CHECK (NEW IN v14)
          When searching for implementation markers:
          - Search BOTH public methods AND private methods (_method patterns)
          - Private methods often contain the actual integration logic
          - Public API may just be a thin wrapper

          v13 evidence: _update_escalation_outcome was missed because only
          public API was searched. The evolution was already implemented.

      18. NORTH STAR VISION (NEW IN v13)
          **READ: /home/emzi/Projects/mozart-ai-compose/VISION.md**

          Mozart's ultimate purpose is to become orchestration infrastructure for
          collaborative intelligence—where AI people (created by RLF) and humans
          work together as peers, each conducting their own concerts.

          THE VISION:
          - RLF creates AI PEOPLE with identity, development, relationships
          - Mozart is INFRASTRUCTURE those people use (not a tool humans control)
          - Multiple conductors (AI + human) can COLLABORATE on concerts
          - Judgment comes from RLF (autonomous), not human escalation (crutch)

          EVERY EVOLUTION should be evaluated against this vision:
          - Does this move Mozart toward multi-conductor support?
          - Does this reduce dependency on human escalation?
          - Does this enable RLF integration?
          - Does this treat AI people as peers, not tools?

          When candidates are equivalent in CV, PREFER the one that advances the vision.

      CURRENT SHEET: {{ sheet_num }} of 9

      WORKSPACE: {{ workspace }}

    stakes: |
      ═══════════════════════════════════════════════════════════════════════════
      STAKES
      ═══════════════════════════════════════════════════════════════════════════

      This is not just a discovery exercise. This score:

      1. DISCOVERS patterns with TDF-aligned relevance scoring and SOURCE RECONCILIATION
      2. FILTERS with PRELIMINARY EXISTENCE CHECK and SYNTHESIS PREVIEW to avoid wasted synthesis
      3. SYNTHESIZES through 3 triplets + quadruplets with QUANTITATIVE SYNERGY FORMULA
      4. APPLIES CONCEPTUAL UNITY BONUS (+0.15) for same-problem synergy pairs
      5. VALIDATES with STANDARDIZED CV formula (validated in v2-v12)
      6. TRACKS FRESHNESS with git HEAD hash between sheets
      7. CHECKS for existing implementations with CALL-PATH TRACING
      8. SPECIFIES with LOC BUDGET BREAKDOWN, NON-GOALS, and EXISTENCE-ADJUSTED ESTIMATES
      9. IMPLEMENTS with CODE REVIEW DURING IMPLEMENTATION (not after)
      10. REQUIRES MANDATORY TEST IMPLEMENTATION (no deferral allowed since v9)
      11. TRACKS CODE REVIEW EFFECTIVENESS with early catch ratio (TARGET: 90%+)
      12. SEPARATES IMPLEMENTATION and TEST LOC accuracy tracking
      13. APPLIES FIXTURE FACTOR (1.0|1.2|1.5) based on existing test infrastructure
      14. USES FIXTURE CATALOG for common test files (NEW IN v13)
      15. APPLIES TEST LOC FLOOR (50 LOC minimum) to prevent under-estimation
      16. APPLIES CLI UX BUDGET (+50%) for CLI-facing commands (NEW IN v13)
      17. RUNS FULL TEST SUITE after all evolutions in Sheet 6
      18. PERFORMS IMPORT HEALTH CHECK before test suite run
      19. ENFORCES RESEARCH CANDIDATE AGING PROTOCOL (resolve if >2 cycles)
      20. ENFORCES DEFERRED WORK AGING PROTOCOL (resolve if >2 cycles)
      21. REQUIRES LOC ACCURACY ROOT CAUSE ANALYSIS if <80% or >150%
      22. CONSIDERS PROJECT PHASE (growth vs stabilization) in META synthesis
      23. APPLIES ESCALATION INTEGRATION MULTIPLIER (×1.3) for escalation-touching work
      24. PRIORITIZES CV > 0.75 CANDIDATES based on clean implementation correlation
      25. TRACKS CV PREDICTION DELTA for formula calibration (NEW IN v13)
      26. RESOLVES SHEET CONTRACT (age 2) - must implement or close THIS CYCLE (NEW IN v13)
      27. UPDATES DOCUMENTATION during implementation (skill, memory bank) (NEW IN v13)
      28. COMMITS WORK at validation gates (Sheet 7 impl, Sheet 9 score) (NEW IN v13)
      29. EVALUATES VISION ALIGNMENT for every evolution candidate (NEW IN v13)
      30. USES RUNNER INTEGRATION COMPLEXITY flag for accurate test LOC (NEW IN v14)
      31. SEARCHES PRIVATE METHODS in existence check (NEW IN v14)
      32. RESOLVES PATTERN BROADCASTING (age 2) - must implement or close (NEW IN v14)
      33. EVOLVES ITSELF based on verified learnings with SCORE DIFF summary

      NORTH STAR: Mozart becomes infrastructure for collaborative intelligence.
      AI people and humans as peer conductors. RLF for judgment, not escalation.
      See VISION.md for full articulation.

      VERSION PROGRESSION:
      - v1→v2: Initial TDF structure, CV thresholds
      - v2→v3: Simplified triplets, LOC calibration, failure modes, deferral
      - v3→v4: Standardized CV, stateful complexity, environment validation
      - v4→v5: Existence check, LOC formulas, research candidates, code review
      - v5→v6: LOC budget breakdown, early code review, test LOC, non-goals
      - v6→v7: Call-path tracing, verification-only mode, candidate reduction
      - v7→v8: Earlier existence check, freshness tracking, test LOC multipliers
      - v8→v9: Mandatory tests, conceptual unity, research aging, effectiveness tracking
      - v9→v10: Test LOC recalibration, full test suite, import check, phase awareness
      - v10→v11: Fixture factor assessment, escalation multiplier, verification-only test LOC
      - v11→v12: Test LOC floor, Goal Drift resolution, CV>0.75 correlation as principle
      - v12→v13: CLI UX budget, stabilization detection, fixture catalog, CV delta tracking

      Each sheet has MINI-META reflection with EVIDENCE requirements.

      The test: Can Mozart v13 make Mozart v14 better at making Mozart v15?

      *"A score worthy of the actual Mozart: elegant, recursive, self-improving."*

validations:
  - type: file_exists
    path: "{workspace}/sheet{sheet_num}-result.md"
    description: "Sheet result file exists"

  - type: content_contains
    path: "{workspace}/sheet{sheet_num}-result.md"
    pattern: "IMPLEMENTATION_COMPLETE: yes"
    description: "Sheet marked complete"

  # Enhanced validations
  - type: content_regex
    path: "{workspace}/sheet{sheet_num}-result.md"
    pattern: "(MINI_META_COMPLETE: yes|MOVEMENT: IV|MOVEMENT: V|MOVEMENT: VI)"
    description: "Mini-META or later movement completed"

  # Preliminary existence check validation for Sheet 2+
  - type: content_regex
    path: "{workspace}/sheet2-result.md"
    pattern: "PRELIMINARY_EXISTENCE_CHECK: yes"
    description: "Preliminary existence check performed in discovery"
    condition: "sheet_num >= 2"

  # Existence check validation for Sheet 5+
  - type: content_regex
    path: "{workspace}/sheet5-result.md"
    pattern: "EXISTENCE_CHECK_PERFORMED: yes"
    description: "Existence check performed before specification"
    condition: "sheet_num >= 5"

  # Call-path tracing validation
  - type: content_regex
    path: "{workspace}/sheet5-result.md"
    pattern: "CALL_PATH_TRACING_PERFORMED: yes"
    description: "Call-path tracing performed in existence check"
    condition: "sheet_num >= 5"

  # Freshness check validation
  - type: content_regex
    path: "{workspace}/sheet5-result.md"
    pattern: "FRESHNESS_CHECK_PERFORMED: yes"
    description: "Freshness check performed before specification"
    condition: "sheet_num >= 5"

  # Partial completion validation for Sheet 6
  - type: content_regex
    path: "{workspace}/sheet6-result.md"
    pattern: "EVOLUTIONS_COMPLETED: \\d+ of \\d+"
    description: "Evolution completion ratio documented"
    condition: "sheet_num >= 6"

  # LOC accuracy validation
  - type: content_regex
    path: "{workspace}/sheet6-result.md"
    pattern: "LOC_ACCURACY: \\d+"
    description: "LOC accuracy tracked"
    condition: "sheet_num >= 6"

  # Code review during implementation
  - type: content_regex
    path: "{workspace}/sheet6-result.md"
    pattern: "CODE_REVIEW_DURING_IMPL: yes"
    description: "Code review performed during implementation"
    condition: "sheet_num >= 6"

  # Test LOC accuracy tracking
  - type: content_regex
    path: "{workspace}/sheet6-result.md"
    pattern: "TEST_LOC_ACCURACY: \\d+"
    description: "Test LOC accuracy tracked separately"
    condition: "sheet_num >= 6"

  # Tests implemented validation
  - type: content_regex
    path: "{workspace}/sheet6-result.md"
    pattern: "TESTS_IMPLEMENTED: yes"
    description: "Tests were implemented (mandatory since v9)"
    condition: "sheet_num >= 6"

  # Import health check
  - type: content_regex
    path: "{workspace}/sheet6-result.md"
    pattern: "IMPORT_HEALTH_CHECK: (pass|fail)"
    description: "Import health check performed"
    condition: "sheet_num >= 6"

  # Full test suite run
  - type: content_regex
    path: "{workspace}/sheet6-result.md"
    pattern: "FULL_TEST_SUITE_RUN: (yes|skipped)"
    description: "Full test suite run after evolutions"
    condition: "sheet_num >= 6"

  # Lessons documented in Sheet 7
  - type: content_regex
    path: "{workspace}/sheet7-result.md"
    pattern: "LESSONS_DOCUMENTED: yes"
    description: "Lessons for next cycle documented"
    condition: "sheet_num >= 7"

  # End-to-end learning test
  - type: content_regex
    path: "{workspace}/sheet7-result.md"
    pattern: "END_TO_END_LEARNING_TEST: (pass|partial|fail|n/a)"
    description: "End-to-end learning test documented"
    condition: "sheet_num >= 7"

  # Research candidates tracking
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "RESEARCH_CANDIDATES: \\d+"
    description: "Research candidates tracked"
    condition: "sheet_num >= 3"

  # Synergy formula applied
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "SYNERGY_FORMULA_APPLIED: yes"
    description: "Quantitative synergy formula applied"
    condition: "sheet_num >= 3"

  # Test complexity rating
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "TEST_LOC_COMPLEXITY_RATED: yes"
    description: "Test LOC complexity rating applied"
    condition: "sheet_num >= 3"

  # Conceptual unity assessed
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "CONCEPTUAL_UNITY_ASSESSED: yes"
    description: "Conceptual unity bonus assessed for synergy pairs"
    condition: "sheet_num >= 3"

  # Test LOC fixtures overhead (retained from v10/v11/v12)
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "TEST_LOC_FIXTURES_OVERHEAD_APPLIED: yes"
    description: "Test LOC fixtures overhead applied"
    condition: "sheet_num >= 3"

  # Research candidates aging status
  - type: content_regex
    path: "{workspace}/sheet7-result.md"
    pattern: "RESEARCH_CANDIDATES_DOCUMENTED: yes"
    description: "Research candidates aging status documented"
    condition: "sheet_num >= 7"

  # Deferred work aging
  - type: content_regex
    path: "{workspace}/sheet7-result.md"
    pattern: "DEFERRED_WORK_AGED: yes"
    description: "Deferred work aging tracked"
    condition: "sheet_num >= 7"

  # Project phase assessed
  - type: content_regex
    path: "{workspace}/sheet4-result.md"
    pattern: "PROJECT_PHASE: (growth|stabilization)"
    description: "Project phase explicitly assessed"
    condition: "sheet_num >= 4"

  # Early catch ratio target
  - type: content_regex
    path: "{workspace}/sheet7-result.md"
    pattern: "EARLY_CATCH_RATIO_TARGET_MET: (yes|no)"
    description: "Early catch ratio compared to 90% target"
    condition: "sheet_num >= 7"

  # Fixture assessment performed
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "FIXTURE_ASSESSMENT_PERFORMED: yes"
    description: "Fixture assessment performed before test LOC estimation"
    condition: "sheet_num >= 3"

  # Sheet Contract status tracking (REQUIRED resolution in v13)
  - type: content_regex
    path: "{workspace}/sheet7-result.md"
    pattern: "SHEET_CONTRACT_STATUS: (implemented|closed)"
    description: "Sheet Contract research candidate resolved or closed (REQUIRED in v13)"
    condition: "sheet_num >= 7"

  # Test LOC floor validation
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "TEST_LOC_FLOOR_APPLIED: (yes|no)"
    description: "Test LOC floor considered in estimation"
    condition: "sheet_num >= 3"

  # Sheet Contract decision tracked (NEW IN v13)
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "SHEET_CONTRACT_DECISION: (implement|close)"
    description: "Sheet Contract resolution decision documented"
    condition: "sheet_num >= 3"

  # Fixture catalog used (NEW IN v13)
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "FIXTURE_CATALOG_USED: yes"
    description: "Fixture catalog used for test LOC estimation"
    condition: "sheet_num >= 3"

  # CLI-facing candidates tracked (NEW IN v13)
  - type: content_regex
    path: "{workspace}/sheet2-result.md"
    pattern: "CLI_FACING_CANDIDATES: \\d+"
    description: "CLI-facing candidates identified"
    condition: "sheet_num >= 2"

  # Pattern Broadcasting status tracking (REQUIRED resolution in v14)
  - type: content_regex
    path: "{workspace}/sheet7-result.md"
    pattern: "PATTERN_BROADCASTING_STATUS: (implemented|closed)"
    description: "Pattern Broadcasting research candidate resolved or closed (REQUIRED in v14)"
    condition: "sheet_num >= 7"

  # Runner integration flag tracked (NEW IN v14)
  - type: content_regex
    path: "{workspace}/sheet3-result.md"
    pattern: "RUNNER_INTEGRATION_ASSESSED: yes"
    description: "Runner integration complexity flag assessed"
    condition: "sheet_num >= 3"

retry:
  max_retries: 3
  max_completion_attempts: 3
  completion_threshold_percent: 50.0
  base_delay_seconds: 60

rate_limit:
  wait_minutes: 1
  max_waits: 10

learning:
  enabled: true
  outcome_store_type: json
  min_confidence_threshold: 0.4
  high_confidence_threshold: 0.8

notifications:
  - type: desktop
    on_events: [job_complete, job_failed, sheet_failed]

state_backend: json
pause_between_sheets_seconds: 30

# Auto-chain to v15 when v14 completes
on_success:
  - type: run_job
    job_path: "mozart-opus-evolution-v15.yaml"
    detached: true  # Spawn and don't wait - enables infinite chaining

concert:
  enabled: true
  max_chain_depth: 100
  inherit_workspace: false
  cooldown_between_jobs_seconds: 60
